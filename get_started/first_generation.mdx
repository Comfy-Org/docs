---
title: "First Image Generation"
description: "This tutorial will guide you through your first image generation with ComfyUI"
---

This guide aims to help you understand ComfyUI's text-to-image functionality and complete your first image generation.

Since most ComfyUI installations don't come with drawing models by default, this tutorial will guide you through:
1. Loading example workflows
2. Automatic model installation and installation locations
3. Using AI drawing models to generate your first text-to-image creation

## Basic Concepts

### About Text-to-Image

Text-to-Image is a fundamental AI drawing feature that generates images from text descriptions. It's one of the most commonly used functions in AI art generation.

Text-to-Image typically requires several basic input conditions:

- Positive prompts: What you want to appear in the image
- Negative prompts: What you don't want to appear in the image
- Drawing model: The model used for generation. Different models can be thought of as different artists

You can think of the entire image generation process as telling your requirements (positive and negative prompts) to an artist (the drawing model), who will then create what you want. In this guide, we'll use SD1.5 as our base model.

### Introduction to SD1.5 Model

**SD1.5 (Stable Diffusion 1.5)** is an AI drawing model developed by [Stability AI](https://stability.ai/). It's the basic version of the Stable Diffusion series, released in 2022. SD1.5 was trained on **512Ã—512** resolution images, so it works best with this resolution. At about 4GB in size, it can run smoothly on **consumer-grade GPUs (like those with 6GB VRAM)**. Currently, SD1.5 has a rich ecosystem supporting various plugins (like ControlNet, LoRA) and optimization tools.

Its lightweight nature, strong compatibility, and rich community ecosystem make it a classic entry-level model in the AI image generation field.

Model characteristics:

Advantages:
- Low entry barrier, mature ecosystem
- Supports various styles including anime, realistic, cartoon
- Fast generation speed

Disadvantages:
- May have multi-subject issues with high resolutions
- Prone to errors in complex details (like hands, lighting layers)
- Limited understanding of complex prompts

## ComfyUI Text-to-Image Workflow Tutorial

### 1. Start ComfyUI

Make sure you've followed the installation guide to start ComfyUI and can successfully open the ComfyUI page

![ComfyUI Interface](/images/interface/comfyui-boot-screen.jpg)

### 2. Load Default Text-to-Image Workflow

Normally, ComfyUI automatically loads the default text-to-image workflow when opened. If your interface is empty, please follow the steps below to load the workflow. If it's already loaded, you can skip this section.

![](/images/tutorial/gettingstarted/first-image-generation-1.jpg)
Follow the numbered steps in the image:
1. Click the **Fit View** button in the bottom right of the ComfyUI interface to ensure any loaded workflow isn't hidden outside the view
2. Click the **folder icon (workflows)** in the sidebar
3. Click the **Browse example workflows** button at the top of the Workflows panel

Continue with the next image:

![Load Workflow](/images/tutorial/gettingstarted/first-image-generation-2-load-workflow.jpg)

4. Select the first default workflow **Image Generation** to load it

### 3. Automatic or Manual Drawing Model Installation

If you don't have the [v1-5-pruned-emaonly-fp16.safetensors](https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/blob/main/v1-5-pruned-emaonly-fp16.safetensors) model installed, you'll see an automatic prompt to download it after loading the text-to-image workflow, as shown below:

![Missing Models](/images/tutorial/gettingstarted/first-image-generation-3-missing-models.jpg)

This is ComfyUI's automatic detection mechanism that appears when a workflow has missing models/nodes.

At this step you can choose to:
1. Click **Download** to let ComfyUI automatically download the model
2. If the download fails or you can't access the download source, refer to the manual download section

#### 3.1 Automatic Model Download

After clicking the **Download** button, ComfyUI will execute the installation. You can wait for it to complete or check the installation progress in the sidebar's model panel.

If the download doesn't succeed after a long time, try the manual installation instructions in this chapter.

#### 3.2 Manual Model Installation

Please visit the model link: [Download v1-5-pruned-emaonly-fp16.safetensors](https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/blob/main/v1-5-pruned-emaonly-fp16.safetensors)

Follow the image below to complete the model download:

![Hugging Face Model Download](/images/tutorial/gettingstarted/first-image-generation-5-hugging-face.jpg)

After downloading, save the **v1-5-pruned-emaonly-fp16.safetensors** file to the following location:

<Tabs>
  <Tab title="ComfyUI Desktop">

    Find your ComfyUI installation location set during installation and save the model file to `<your ComfyUI installation location>/ComfyUI/models/checkpoints`

    ![ComfyUI Desktop Model Save Location](/images/tutorial/gettingstarted/first-image-generation-6-1-portable.jpg)

  </Tab>
  <Tab title="ComfyUI Portable">
    Find your extracted portable version folder and save the model in the **ComfyUI_windows_portable/ComfyUI/models/checkpoints** folder
    ![ComfyUI Portable Model Save Location](/images/tutorial/gettingstarted/first-image-generation-6-1-portable.jpg)
  </Tab>
  <Tab title="Other Versions">
    Please refer to the Desktop and Portable version instructions to find the **ComfyUI/models/checkpoints** folder location
  </Tab>
</Tabs>

After saving, refresh or restart ComfyUI to ensure the model is detected.

### 4. Load Model and Generate Your First Image

After installing the drawing model, follow these steps to load the model and generate your first image:

![Image Generation](/images/tutorial/gettingstarted/first-image-generation-7-queue.jpg)
Follow the numbered steps in the image:
1. In the **Load Checkpoint** node, use the arrows or click the text area to ensure **v1-5-pruned-emaonly-fp16.safetensors** is selected, and the left/right arrows don't show **null** text
2. Click the `Queue` button or use the shortcut `Ctrl + enter` to execute image generation

After the process completes, you should see the generated image in the **Save Image** node. You can right-click on it to save it locally.

![ComfyUI First Image Generation Result](/images/tutorial/gettingstarted/first-image-generation-8-result.jpg)

### 5. Workflow Explanation

![ComfyUI Text-to-Image Workflow Explanation](/images/tutorial/gettingstarted/first-image-generation-9-explain.jpg)

As shown in the image, here's what each node does:
A. **Load Checkpoint**: Loads the drawing model
B. **CLIP Text Encoder**: Encodes prompts - your image requirements. Connection to Ksampler's `Positive` is for positive prompts, to `Negative` for negative prompts
C. **Empty Latent Image**: Defines a latent space - think of it as canvas size
D. **KSampler**: Processes input conditions in latent space to generate a latent image
E. **VAE Decode**: Converts latent space image to viewable image
F. **Save Image**: Previews and saves the decoded image to the local `ComfyUI/output` folder

Try modifying the text in the **CLIP Text Encoder** to see how different prompts create different effects or generate the images you want.

### 6. Start Your Own Experiments

Try modifying the text in the **CLIP Text Encoder** to see how different prompts create different effects or generate images you want. Here are some simple principles for the SD1.5 model:
- Use English when possible
- Use phrases rather than long sentences
- Use more specific descriptions
- Use expressions like `(golden hour:1.2)` to increase specific keyword weights - making them more likely to appear in the image. `1.2` is the weight, `golden hour` is the keyword
- Use keywords like `masterpiece, best quality, 4k` to improve generation quality

Here are some prompt examples to try, or use your own prompts to experiment:

1. Anime Style

Positive prompt:
```
anime style, 1girl with long pink hair, cherry blossom background, studio ghibli aesthetic, soft lighting, intricate details

masterpiece, best quality, 4k
```

Negative prompt:
```
low quality, blurry, deformed hands, extra fingers
```

2. Realistic Style

Positive prompt:
```
(ultra realistic portrait:1.3), (elegant woman in crimson silk dress:1.2), 
full body, soft cinematic lighting, (golden hour:1.2), 
(fujifilm XT4:1.1), shallow depth of field, 
(skin texture details:1.3), (film grain:1.1), 
gentle wind flow, warm color grading, (perfect facial symmetry:1.3)
```

Negative prompt:
```
(deformed, cartoon, anime, doll, plastic skin, overexposed, blurry, extra fingers)
```

3. Specific Artist Style

Positive prompt:
```
fantasy elf, detailed character, glowing magic, vibrant colors, long flowing hair, elegant armor, ethereal beauty, mystical forest, magical aura, high detail, soft lighting, fantasy portrait, Artgerm style
```

Negative prompt:
```
blurry, low detail, cartoonish, unrealistic anatomy, out of focus, cluttered, flat lighting
```

## Troubleshooting

### 1. Model Loading Issues

If the `Load Checkpoint` node shows no models to select from, first verify your model installation location is correct, or try **refreshing the browser** or **restarting ComfyUI** to detect models in the corresponding folder.

### 2. Image Quality Improvement

If you encounter issues like deformed hands, try:

- Adding "deformed hands, extra fingers" to negative prompts
- Using post-processing plugins like ADetailer
- Slightly increasing the CFG value (not exceeding 12)
