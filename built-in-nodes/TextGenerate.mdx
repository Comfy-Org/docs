---
title: "TextGenerate - ComfyUI Built-in Node Documentation"
description: "The TextGenerate node uses a CLIP model to create text based on a user's prompt. It can optionally use an image as a visual reference to guide the text generation. You can control the length of the..."
sidebarTitle: "TextGenerate"
icon: "circle"
mode: wide
---
> This documentation was AI-generated. If you find any errors or have suggestions for improvement, please feel free to contribute! [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/TextGenerate/en.md)

The TextGenerate node uses a CLIP model to create text based on a user's prompt. It can optionally use an image as a visual reference to guide the text generation. You can control the length of the output and choose whether to use random sampling with various settings or to generate text without sampling.

## Inputs

| Parameter | Data Type | Required | Range | Description |
|-----------|-----------|----------|-------|-------------|
| `clip` | CLIP | Yes | N/A | The CLIP model used for tokenizing the prompt and generating text. |
| `prompt` | STRING | Yes | N/A | The text prompt that guides the generation. This field supports multiple lines and dynamic prompts. The default value is an empty string. |
| `image` | IMAGE | No | N/A | An optional image that can be used alongside the text prompt to influence the generated text. |
| `max_length` | INT | Yes | 1 to 2048 | The maximum number of tokens the model will generate. The default value is 256. |
| `sampling_mode` | COMBO | Yes | `"on"`<br />`"off"` | Controls whether random sampling is used during text generation. When set to "on", additional parameters for controlling the sampling become available. The default is "on". |
| `temperature` | FLOAT | No | 0.01 to 2.0 | Controls the randomness of the output. Lower values make the output more predictable, higher values make it more creative. This parameter is only available when `sampling_mode` is "on". The default value is 0.7. |
| `top_k` | INT | No | 0 to 1000 | Limits the sampling pool to the top K most likely next tokens. A value of 0 disables this filter. This parameter is only available when `sampling_mode` is "on". The default value is 64. |
| `top_p` | FLOAT | No | 0.0 to 1.0 | Uses nucleus sampling, limiting choices to tokens whose cumulative probability is less than this value. This parameter is only available when `sampling_mode` is "on". The default value is 0.95. |
| `min_p` | FLOAT | No | 0.0 to 1.0 | Sets a minimum probability threshold for tokens to be considered. This parameter is only available when `sampling_mode` is "on". The default value is 0.05. |
| `repetition_penalty` | FLOAT | No | 0.0 to 5.0 | Penalizes tokens that have already been generated to reduce repetition. A value of 1.0 applies no penalty. This parameter is only available when `sampling_mode` is "on". The default value is 1.05. |
| `seed` | INT | No | 0 to 18446744073709551615 | A number used to initialize the random number generator for reproducible results when sampling is "on". The default value is 0. |

**Note:** The parameters `temperature`, `top_k`, `top_p`, `min_p`, `repetition_penalty`, and `seed` are only active and visible in the node interface when the `sampling_mode` is set to "on".

## Outputs

| Output Name | Data Type | Description |
|-------------|-----------|-------------|
| `generated_text` | STRING | The text generated by the model based on the input prompt and optional image. |
