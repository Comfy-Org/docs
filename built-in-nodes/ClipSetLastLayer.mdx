---
title: "ClipSetLastLayer - ComfyUI Built-in Node Documentation"
description: "The ClipSetLastLayer node is used to control the processing depth of CLIP models."
sidebarTitle: "ClipSetLastLayer"
icon: "circle"
---

`CLIP Set Last Layer` is a core node in ComfyUI for controlling the processing depth of CLIP models. It allows users to precisely control where the CLIP text encoder stops processing, affecting both the depth of text understanding and the style of generated images.

Imagine the CLIP model as a 24-layer intelligent brain:

- Shallow layers (1-8): Recognize basic letters and words
- Middle layers (9-16): Understand grammar and sentence structure
- Deep layers (17-24): Grasp abstract concepts and complex semantics

`CLIP Set Last Layer` works like a **"thinking depth controller"**:

-1: Use all 24 layers (complete understanding)
-2: Stop at layer 23 (slightly simplified)
-12: Stop at layer 13 (medium understanding)
-24: Use only layer 1 (basic understanding)

## Inputs

| Parameter | Data Type | Default | Range | Description |
|-----------|-----------|---------|--------|-------------|
| `clip` | CLIP | - | - | The CLIP model to be modified |
| `stop_at_clip_layer` | INT | -1 | -24 to -1 | Specifies which layer to stop at, -1 uses all layers, -24 uses only the first layer |

## Outputs

| Output Name | Data Type | Description |
|-------------|-----------|-------------|
| clip | CLIP | The modified CLIP model with the specified layer set as the last one |

## Why Set the Last Layer

- **Performance Optimization**: Like not needing a PhD to understand simple sentences, sometimes shallow understanding is enough and faster
- **Style Control**: Different levels of understanding produce different artistic styles
- **Compatibility**: Some models might perform better at specific layers
