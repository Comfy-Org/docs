---
title: "HunyuanVideo15SuperResolution - ComfyUI Built-in Node Documentation"
description: "The HunyuanVideo15SuperResolution node prepares conditioning data for a video super-resolution process. It takes a latent representation of a video and, optionally, a starting image, and packages t..."
sidebarTitle: "HunyuanVideo15SuperResolution"
icon: "circle"
---
> This documentation was AI-generated. If you find any errors or have suggestions for improvement, please feel free to contribute! [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/HunyuanVideo15SuperResolution/en.md)

The HunyuanVideo15SuperResolution node prepares conditioning data for a video super-resolution process. It takes a latent representation of a video and, optionally, a starting image, and packages them along with noise augmentation and CLIP vision data into a format that can be used by a model to generate a higher-resolution output.

## Inputs

| Parameter | Data Type | Required | Range | Description |
|-----------|-----------|----------|-------|-------------|
| `positive` | CONDITIONING | Yes | N/A | The positive conditioning input to be modified with latent and augmentation data. |
| `negative` | CONDITIONING | Yes | N/A | The negative conditioning input to be modified with latent and augmentation data. |
| `vae` | VAE | No | N/A | The VAE used to encode the optional `start_image`. Required if `start_image` is provided. |
| `start_image` | IMAGE | No | N/A | An optional starting image to guide the super-resolution. If provided, it will be upscaled and encoded into the conditioning latent. |
| `clip_vision_output` | CLIP_VISION_OUTPUT | No | N/A | Optional CLIP vision embeddings to add to the conditioning. |
| `latent` | LATENT | Yes | N/A | The input latent video representation that will be incorporated into the conditioning. |
| `noise_augmentation` | FLOAT | No | 0.0 - 1.0 | The strength of noise augmentation to apply to the conditioning (default: 0.70). |

**Note:** If you provide a `start_image`, you must also connect a `vae` for it to be encoded. The `start_image` will be automatically upscaled to match the dimensions implied by the input `latent`.

## Outputs

| Output Name | Data Type | Description |
|-------------|-----------|-------------|
| `positive` | CONDITIONING | The modified positive conditioning, now containing the concatenated latent, noise augmentation, and optional CLIP vision data. |
| `negative` | CONDITIONING | The modified negative conditioning, now containing the concatenated latent, noise augmentation, and optional CLIP vision data. |
| `latent` | LATENT | The input latent is passed through unchanged. |
