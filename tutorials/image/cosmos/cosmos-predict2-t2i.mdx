---
title: "Cosmos Predict2 Text-to-Image ComfyUI Official Example"
description: "This guide demonstrates how to complete Cosmos-Predict2 text-to-image workflow in ComfyUI"
sidebarTitle: "Cosmos-Predict2"
---

import UpdateReminder from '/snippets/tutorials/update-reminder.mdx'

Cosmos-Predict2 is NVIDIA's next-generation physical world foundation model, specifically designed for high-quality visual generation and prediction tasks in physical AI scenarios.
The model features exceptional physical accuracy, environmental interactivity, and detail reproduction capabilities, enabling realistic simulation of complex physical phenomena and dynamic scenes.

Cosmos-Predict2 supports various generation methods including Text-to-Image (Text2Image) and Video-to-World (Video2World), and is widely used in industrial simulation, autonomous driving, urban planning, scientific research, and other fields.

GitHub:[Cosmos-predict2](https://github.com/nvidia-cosmos/cosmos-predict2)
huggingface: [Cosmos-Predict2](https://huggingface.co/collections/nvidia/cosmos-predict2-68028efc052239369a0f2959)


This guide will walk you through completing **text-to-image** workflow in ComfyUI.

For the video generation section, please refer to the following part:

<Card title="Cosmos Predict2 Video Generation" icon="book" href="/tutorials/video/cosmos/cosmos-predict2-video2world">
  Using Cosmos-Predict2  for video generation
</Card>

<UpdateReminder/>
{/* 
## Cosmos Predict2 Video2World Workflow

When testing the 2B version showed it uses around 16GB of VRAM.

### 1. Workflow File

Please download the image below and drag it into ComfyUI to load the workflow. The workflow already has embedded model download links.

![Input Image](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/cosmos/predict2/cosmos_predict2_2B_t2i.png)


### 2. Manual Model Installation

If the model download wasn't successful, you can try to download them manually by yourself in this section.

**Diffusion model**

- [cosmos_predict2_2B_t2i.safetensors](https://huggingface.co/Comfy-Org/Cosmos_Predict2_repackaged/resolve/main/cosmos_predict2_2B_t2i.safetensors)

For other weights, please visit [Cosmos_Predict2_repackaged](https://huggingface.co/Comfy-Org/Cosmos_Predict2_repackaged) to download

**Text encoder**

[oldt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/cosmos_1.0_text_encoder_and_VAE_ComfyUI/resolve/main/text_encoders/oldt5_xxl_fp8_e4m3fn_scaled.safetensors)

**VAE**

[wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors)


File Storage Location
```
ðŸ“‚ ComfyUI/
â”œâ”€â”€ðŸ“‚ models/
â”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/
â”‚   â”‚   â””â”€â”€â”€ cosmos_predict2_2B_t2i.safetensors
â”‚   â”œâ”€â”€ ðŸ“‚ text_encoders/
â”‚   â”‚   â””â”€â”€â”€ oldt5_xxl_fp8_e4m3fn_scaled.safetensors
â”‚   â””â”€â”€ ðŸ“‚ vae/
â”‚       â””â”€â”€  wan_2.1_vae.safetensors
```

### 3. Complete Workflow Step by Step

![Workflow Step Guide](/images/tutorial/image/cosmos/cosmos_predict2_2B_t2i_step_guide.jpg)

Please follow the steps in the image to run the workflow:

1. Ensure the `Load Diffusion Model` node has loaded `cosmos_predict2_2B_t2i.safetensors`
2. Ensure the `Load CLIP` node has loaded `oldt5_xxl_fp8_e4m3fn_scaled.safetensors`
3. Ensure the `Load VAE` node has loaded `wan_2.1_vae.safetensors`
4. Set the image size in `EmptySD3LatentImage`
5. Modify the prompts in the `ClipTextEncode` node
6. Click the `Run` button or use the shortcut `Ctrl(cmd) + Enter` to run the workflow
7. Once generation is complete, the image will automatically save to the `ComfyUI/output/` directory. You can also preview it in the `save image` node. */}