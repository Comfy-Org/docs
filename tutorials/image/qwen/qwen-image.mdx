---
title: "Qwen-Image ComfyUI Native Workflow Example"
description: "Qwen-Image is a 20B parameter MMDiT (Multimodal Diffusion Transformer) model open-sourced under the Apache 2.0 license."
sidebarTitle: "Qwen-Image"
---

import UpdateReminder from '/snippets/tutorials/update-reminder.mdx'


**Qwen-Image** is the first image generation foundation model released by Alibaba's Qwen team. It's a 20B parameter MMDiT (Multimodal Diffusion Transformer) model open-sourced under the Apache 2.0 license. The model has made significant advances in **complex text rendering** and **precise image editing**, achieving high-fidelity output for multiple languages including English and Chinese.

**Model Highlights**:
- **Excellent Multilingual Text Rendering**: Supports high-precision text generation in multiple languages including English, Chinese, Korean, Japanese, maintaining font details and layout consistency
- **Diverse Artistic Styles**: From photorealistic scenes to impressionist paintings, from anime aesthetics to minimalist design, fluidly adapting to various creative prompts

**Related Links**:
 - [GitHub](https://github.com/QwenLM/Qwen-Image)
 - [Hugging Face](https://huggingface.co/Qwen/Qwen-Image)
 - [ModelScope](https://modelscope.cn/models/qwen/Qwen-Image)

## Qwen-Image Native Workflow Example

<UpdateReminder />

**VRAM usage reference**

Tested with **RTX 4090D 24GB**

 Model Version: Qwen-Image_fp8
- VRAM: 86%
- Generation time: 94s for the first time, 71s for the second time

**Model Version: Qwen-Image_bf16**
- VRAM: 96%
- Generation time: 295s for the first time, 131s for the second time


### 1. Workflow File

After updating ComfyUI, you can find the workflow file in the templates, or drag the workflow below into ComfyUI to load it.
![Qwen-image Text-to-Image Workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/image/qwen/qwen-image.png)

<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_qwen_image.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>Download JSON Workflow</p>
</a>
### 2. Model Download

**Available Models in ComfyUI**

- Qwen-Image_bf16 (40.9 GB)
- Qwen-Image_fp8 (20.4 GB)
- Distilled versions (non-official, requires only 15 steps)

All models are available at [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) and [Modelscope](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files)

**Diffusion Model**

[qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)

The following models are unofficial distilled versions that require only 15 steps.
[Distilled Versions](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main/non_official/diffusion_models)
- [qwen_image_distill_full_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_bf16.safetensors) 40.9 GB
- [qwen_image_distill_full_fp8.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_fp8_e4m3fn.safetensors) 20.4 GB

<Note>
 - The original author of the distilled version recommends using 15 steps with cfg 1.0.
- According to tests, this distilled version also performs well at 10 steps with cfg 1.0. You can choose euler or res_multistep according to your desired image type.
</Note>

**Text Encoder**

[qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)

**VAE**

[qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)

**Model Storage Location**

```
ðŸ“‚ ComfyUI/
â”œâ”€â”€ ðŸ“‚ models/
â”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/
â”‚   â”‚   â””â”€â”€ qwen_image_fp8_e4m3fn.safetensors
â”‚   â”œâ”€â”€ ðŸ“‚ vae/
â”‚   â”‚   â””â”€â”€ qwen_image_vae.safetensors
â”‚   â””â”€â”€ ðŸ“‚ text_encoders/
â”‚       â””â”€â”€ qwen_2.5_vl_7b_fp8_scaled.safetensors
```
### 3. Complete the Workflow Step by Step

![Step Guide](/images/tutorial/image/qwen/image_qwen_image-guide.jpg)

1. Load `qwen_image_fp8_e4m3fn.safetensors` in the `Load Diffusion Model` node
2. Load `qwen_2.5_vl_7b_fp8_scaled.safetensors` in the `Load CLIP` node  
3. Load `qwen_image_vae.safetensors` in the `Load VAE` node
4. Set image dimensions in the `EmptySD3LatentImage` node
5. Enter your prompts in the `CLIP Text Encoder` (supports English, Chinese, Korean, Japanese, Italian, etc.)
6. Click Queue or press `Ctrl+Enter` to run