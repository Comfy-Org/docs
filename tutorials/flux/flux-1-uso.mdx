---
title: "ByteDance USO ComfyUI Native Workflow example"
description: "Unified Style and Subject-Driven Generation with ByteDance's USO model"
sidebarTitle: "ByteDance USO"
---

import UpdateReminder from '/snippets/tutorials/update-reminder.mdx'

**USO (Unified Style-Subject Optimized)** is a model developed by ByteDance's UXO Team that unifies style-driven and subject-driven generation tasks. 
Built on FLUX.1-dev architecture, the model achieves both style similarity and subject consistency through disentangled learning and style reward learning (SRL).

USO supports three main approaches:
- **Subject-Driven**: Place subjects into new scenes while maintaining identity consistency
- **Style-Driven**: Apply artistic styles to new content based on reference images  
- **Combined**: Use both subject and style references simultaneously

**Related Links**
- [Project Page](https://bytedance.github.io/USO/)
- [GitHub](https://github.com/bytedance/USO)
- [Model Weights](https://huggingface.co/bytedance-research/USO)

## ByteDance USO ComfyUI Native Workflow

<UpdateReminder/>

### 1. Workflow and input

Download the image below and drag it into ComfyUI to load the corresponding workflow.

![Workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/flux/bytedance-uso/bytedance-uso.png)

<a 
className="prose"
target='_blank'
href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/flux1_dev_uso_reference_image_gen.json"
style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}
>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>Download JSON Workflow</p>
</a>

Use the image below as an input image.

![input](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/flux/bytedance-uso/input.png)

### 2. Model links


**checkpoints**

- [flux1-dev-fp8.safetensors](https://huggingface.co/Comfy-Org/flux1-dev/resolve/main/flux1-dev-fp8.safetensors)

**loras**

- [uso-flux1-dit-lora-v1.safetensors](https://huggingface.co/Comfy-Org/USO_1.0_Repackaged/resolve/main/split_files/loras/uso-flux1-dit-lora-v1.safetensors)

**model_patches**

- [uso-flux1-projector-v1.safetensors](https://huggingface.co/Comfy-Org/USO_1.0_Repackaged/resolve/main/split_files/model_patches/uso-flux1-projector-v1.safetensors)

**clip_visions**
- [sigclip_vision_patch14_384.safetensors](https://huggingface.co/Comfy-Org/sigclip_vision_384/resolve/main/sigclip_vision_patch14_384.safetensors)

Please download all models and place them in the following directories:

```
ðŸ“‚ ComfyUI/
â”œâ”€â”€ ðŸ“‚ models/
â”‚   â”œâ”€â”€ ðŸ“‚ checkpoints/
â”‚   â”‚   â””â”€â”€ flux1-dev-fp8.safetensors
â”‚   â”œâ”€â”€ ðŸ“‚ loras/
â”‚   â”‚   â””â”€â”€ uso-flux1-dit-lora-v1.safetensors
â”‚   â”œâ”€â”€ ðŸ“‚ model_patches/
â”‚   â”‚   â””â”€â”€ uso-flux1-projector-v1.safetensors
â”‚   â”œâ”€â”€ ðŸ“‚ clip_visions/
â”‚   â”‚   â””â”€â”€ sigclip_vision_patch14_384.safetensors
```


### 3. Workflow instructions

![Workflow instructions](/images/tutorial/flux/flux1_uso_reference_image_gen.jpg)

1. Load models:
    - 1.1 Ensure the `Load Checkpoint` node has `flux1-dev-fp8.safetensors` loaded
    - 1.2 Ensure the `LoraLoaderModelOnly` node has `dit_lora.safetensors` loaded
    - 1.3 Ensure the `ModelPatchLoader` node has `projector.safetensors` loaded
    - 1.4 Ensure the `Load CLIP Vision` node has `sigclip_vision_patch14_384.safetensors` loaded
2. Content Reference:
    - 2.1 Click `Upload` to upload the input image we provided
    - 2.2 The `ImageScaleToMaxDimension` node will scale your input image for content reference, 512px will keep more character features, but if you only use the character's head as input, the final output image often has issues like the character taking up too much space. Setting it to 1024px gives much better results.  
3. In the example, we only use the `content reference` image input. If you want to use the `style reference` image input, you can use `Ctrl-B` to bypass the marked node group.
4. Write your prompt or keep default
5. Set the image size if you need
6. The EasyCache node is for inference acceleration, but it will also sacrifice some quality and details. You can bypass it (Ctrl+B) if you don't need to use it.
7. Click the `Run` button, or use the shortcut `Ctrl(Cmd) + Enter` to run the workflow

### 4. Additional Notes

1. Style reference only:

We also provide a workflow that only uses style reference in the same workflow we provided

![Workflow](/images/tutorial/flux/flux1_uso_reference_image_gen_style_reference_only.jpg)
The only different is we replaced the `content reference` node and only use an `Empty Latent Image` node.

2. You can also bypass whole `Style Reference` group and use the workflow as a text to image workflow, which means this workflow has 4 variations
- Only use content (subject) reference
- Only use style reference
- Mixed content and style reference
- As a text to image workflow
