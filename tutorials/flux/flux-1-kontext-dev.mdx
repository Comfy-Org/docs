---
title: "ComfyUI Flux Kontext Dev Native Workflow Example"
description: "ComfyUI Flux Kontext Dev Native Workflow Example."
sidebarTitle: "Flux.1 Kontext Dev"
---

import PromptTechniques from "/snippets/tutorials/flux/prompt-techniques.mdx";
import UpdateReminder from '/snippets/tutorials/update-reminder.mdx'

<iframe
  className="w-full aspect-video rounded-xl"
  src="https://www.youtube.com/embed/Y7L_cbNJHj0?si=zuaRiU3qJYMNW2uv"
  title="ComfyUI Selection Toolbox New Features"
  allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

## About FLUX.1 Kontext Dev

FLUX.1 Kontext is a breakthrough multimodal image editing model from Black Forest Labs that supports simultaneous text and image input, intelligently understanding image context and performing precise editing. Its development version is an open-source diffusion transformer model with 12 billion parameters, featuring excellent context understanding and character consistency maintenance, ensuring that key elements such as character features and composition layout remain stable even after multiple iterative edits.

It shares the same core capabilities as the FLUX.1 Kontext suite:
- Character Consistency: Preserves unique elements in images across multiple scenes and environments, such as reference characters or objects in the image.
- Editing: Makes targeted modifications to specific elements in the image without affecting other parts.
- Style Reference: Generates novel scenes while preserving the unique style of the reference image according to text prompts.
- Interactive Speed: Minimal latency in image generation and editing.

While the previously released API version offers the highest fidelity and speed, FLUX.1 Kontext [Dev] runs entirely on local machines, providing unparalleled flexibility for developers, researchers, and advanced users who wish to experiment.

### Version Information

- **[FLUX.1 Kontext [pro]** - Commercial version, focused on rapid iterative editing
- **FLUX.1 Kontext [max]** - Experimental version with stronger prompt adherence
- **FLUX.1 Kontext [dev]** - Open source version (used in this tutorial), 12B parameters, mainly for research

Currently in ComfyUI, you can use all these versions, where [Pro and Max versions](/tutorials/partner-nodes/black-forest-labs/flux-1-kontext) can be called through API nodes, while the Dev open source version please refer to the instructions in this guide.

<UpdateReminder/>

## Model Download

To run the workflows in this guide successfully, you first need to download the following model files. You can also directly get the model download links from the corresponding workflows, which already contain the model file download information.

**Diffusion Model**

- [flux1-dev-kontext_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors)

<Tip>
If you want to use the original weights, you can visit Black Forest Labs' related repository to obtain and use the original model weights.
</Tip>

**VAE**
- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)

**Text Encoder**
- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)
- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)

Model save location

```
ðŸ“‚ ComfyUI/
â”œâ”€â”€ ðŸ“‚ models/
â”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/
â”‚   â”‚   â””â”€â”€ flux1-dev-kontext_fp8_scaled.safetensors
â”‚   â”œâ”€â”€ ðŸ“‚ vae/
â”‚   â”‚   â””â”€â”€ ae.safetensor
â”‚   â””â”€â”€ ðŸ“‚ text_encoders/
â”‚       â”œâ”€â”€ clip_l.safetensors
â”‚       â””â”€â”€ t5xxl_fp16.safetensors or t5xxl_fp8_e4m3fn_scaled.safetensors
```

## Flux.1 Kontext Dev Workflow

This workflow uses the `Load Image(from output)` node to load the image to be edited, making it more convenient for you to access the edited image for multiple rounds of editing.

### 1. Workflow and Input Image Download

Download the following files and drag them into ComfyUI to load the corresponding workflow

![ComfyUI Flux.1 Kontext Pro Image API Node Workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/flux/kontext/dev/flux_1_kontext_dev_basic.png)

**Input Image**

![ComfyUI Flux Kontext Native Workflow Input](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/flux/kontext/dev/rabbit.jpg)

### 2. Complete the workflow step by step

![Workflow Step Guide](/images/tutorial/flux/flux_1_kontext_dev_basic_step_guide.jpg)
You can refer to the numbers in the image to complete the workflow run:

1. In the `Load Diffusion Model` node, load the `flux1-dev-kontext_fp8_scaled.safetensors` model
2. In the `DualCLIP Load` node, ensure that `clip_l.safetensors` and `t5xxl_fp16.safetensors` or `t5xxl_fp8_e4m3fn_scaled.safetensors` are loaded
3. In the `Load VAE` node, ensure that `ae.safetensors` model is loaded
4. In the `Load Image(from output)` node, load the provided input image
5. In the `CLIP Text Encode` node, modify the prompts, only English is supported
6. Click the `Queue` button, or use the shortcut `Ctrl(cmd) + Enter` to run the workflow

<PromptTechniques/>