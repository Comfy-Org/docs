---
title: "ComfyUI Image to Image Workflow"
sidebarTitle: "Image to Image"
description: "This guide will help you understand and complete an image to image workflow"
---

## What is Image to Image

Image to Image is a workflow in ComfyUI that allows users to input an image and generate a new image based on it.

Image to Image can be used in scenarios such as:
- Converting original image styles, like transforming realistic photos into artistic styles
- Converting line art into realistic images
- Image restoration
- Colorizing old photos
- ... and other scenarios

To explain it with an analogy:
It's like asking an artist to create a specific piece based on your reference image.

If you carefully compare this tutorial with the [Text to Image](/tutorials/basic/text-to-image) tutorial, you'll notice that the Image to Image process is very similar to Text to Image, just with an additional input reference image as a condition. In Text to Image, we let the artist (image model) create freely based on our prompts, while in Image to Image, we let the artist create based on both our reference image and prompts.

## ComfyUI Image to Image Workflow Example Guide

### 1. Preparation

Download the model file below and save it to the `ComfyUI/models/checkpoints` directory,
- [v1-5-pruned-emaonly-fp16.safetensors](https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/blob/main/v1-5-pruned-emaonly-fp16.safetensors)

Please download the image below.
then **drag it** into the ComfyUI interface or use the menu **Workflow** --> **Open (shortcut `Ctrl + O`)** to load this workflow

![Example Image](/images/tutorial/basic/img2img/input.jpeg)

Save the image below, then drag and drop to ComfyUI  it to load the corresponding workflow
![Image to Image Workflow](/images/tutorial/basic/img2img/image_to_image.png)

### 2. Starting the Image to Image Workflow

![ComfyUI Image to Image Workflow - Steps](/images/tutorial/basic/img2img/image-to-image-02-guide.jpg)

After loading the Image to Image workflow, please follow these numbered steps while referring to the image to complete the example workflow generation:
1. Load your local image model in the **Load Checkpoint** node
2. Click the `upload` button in the **Load Image** node to upload the image provided in the preparation step
3. Click the `Queue` button or use the shortcut `Ctrl + Enter` to execute the image generation

## Start Your Own Experiments

1. Try modifying the `denoise` parameter in the **KSampler** node, gradually changing it from 1 to 0, and observe the changes in the generated images
2. Replace with your own prompts and reference images to generate your own image effects

## Key Points of Image to Image Workflow

The key to the Image to Image workflow lies in the `denoise` parameter in the `KSampler` node, which should be **less than 1**

If you've adjusted the `denoise` parameter and generated images, you'll notice:
- The smaller the `denoise` value, the smaller the difference between the generated image and the reference image
- The larger the `denoise` value, the larger the difference between the generated image and the reference image

This is because `denoise` determines the strength of noise added to the latent space image after converting the reference image. If `denoise` is 1, the latent space image will become completely random noise, making it the same as the latent space generated by the `empty latent image` node, losing all characteristics of the reference image.

For the corresponding principles, please refer to the principle explanation in the [Text to Image](/tutorials/basic/text-to-image) tutorial.