---
title: "Stability AI Stable Diffusion 3.5 API Node ComfyUI Official Example"
description: "This article will introduce how to use Stability AI Stable Diffusion 3.5 API node's text-to-image and image-to-image capabilities in ComfyUI"
sidebarTitle: "Stable Diffusion 3.5 Image"
---

import ReqHint from "/snippets/tutorials/api-nodes/req-hint.mdx";
import UpdateReminder from "/snippets/tutorials/update-reminder.mdx";

The [Stability AI Stable Diffusion 3.5 Image](/built-in-nodes/api-node/image/stability-ai/stability-ai-stable-diffusion-3-5-image) node allows you to use Stability AI's Stable Diffusion 3.5 model to create high-quality, detail-rich image content through text prompts or reference images.

In this guide, we will show you how to set up workflows for both text-to-image and image-to-image generation using this node.

<ReqHint/>
<UpdateReminder/>

## Stability AI Stable Diffusion 3.5 Text-to-Image Workflow

### 1. Workflow File Download

The image below contains workflow information in its `metadata`. Please download and drag it into ComfyUI to load the corresponding workflow.

![Stability AI Stable Diffusion 3.5 Text-to-Image Workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/stability_ai/stable_diffusion_3-5-t2i.png)

### 2. Complete the Workflow Step by Step

![Stability AI Stable Diffusion 3.5 Text-to-Image Step Guide](/images/tutorial/api_nodes/stability_ai/stable_diffusion_3_5_image_t2i_step_guide.jpg)

You can follow the numbered steps in the image to complete the basic text-to-image workflow:
1. (Optional) Modify the `prompt` parameter in the `Stability AI Stable Diffusion 3.5 Image` node to input your desired image description. More detailed prompts often result in better image quality.
2. (Optional) Select the `model` parameter to choose which SD 3.5 model version to use.
3. (Optional) Select the `style_preset` parameter to control the visual style of the image. Different presets produce images with different stylistic characteristics, such as "cinematic" or "anime". Select "None" to not apply any specific style.
4. (Optional) Edit the `String(Multiline)` to modify negative prompts, specifying elements you don't want to appear in the generated image.
5. Click the `Run` button or use the shortcut `Ctrl(cmd) + Enter` to execute the image generation.
6. After the API returns results, you can view the generated image in the `Save Image` node. The image will also be saved to the `ComfyUI/output/` directory.

### 3. Additional Notes

- **Prompt**: The prompt is one of the most important parameters in the generation process. Detailed, clear descriptions lead to better results. Can include elements like scene, subject, colors, lighting, and style.
- **CFG Scale**: Controls how closely the generator follows the prompt. Higher values make the image more closely match the prompt description, but too high may result in oversaturated or unnatural results.
- **Style Preset**: Offers various preset styles for quickly defining the overall style of the image.
- **Negative Prompt**: Used to specify elements you don't want to appear in the generated image.
- **Seed Parameter**: Can be used to reproduce or fine-tune generation results, helpful for iteration during creation.
- Currently the `Load Image` node is in "Bypass" mode. To enable it, refer to the step guide and right-click the node to set "Mode" to "Always" to enable input, switching to image-to-image mode.
- `image_denoise` has no effect when there is no input image.

## Stability AI Stable Diffusion 3.5 Image-to-Image Workflow

### 1. Workflow File Download

The image below contains workflow information in its `metadata`. Please download and drag it into ComfyUI to load the corresponding workflow.

![Stability AI Stable Diffusion 3.5 Image-to-Image Workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/stability_ai/sd3-5-i2i/stable_diffusion_3_5-i2i.png)

Download the image below to use as input
![Stability AI Stable Diffusion 3.5 Image-to-Image Workflow Input Image](![Stability AI Stable Diffusion 3.5 图生图工作流输入图片](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/stability_ai/sd3-5-i2i/input.jpg)


### 2. Complete the Workflow Step by Step

![Stability AI Stable Diffusion 3.5 Image-to-Image Step Guide](/images/tutorial/api_nodes/stability_ai/stable_diffusion_3_5_image_i2i_step_guide.jpg)

You can follow the numbered steps in the image to complete the image-to-image workflow:
1. Load a reference image through the `Load Image` node, which will serve as the basis for generation.
2. (Optional) Modify the `prompt` parameter in the `Stability AI Stable Diffusion 3.5 Image` node to describe elements you want to change or enhance in the reference image.
3. (Optional) Select the `style_preset` parameter to control the visual style of the image. Different presets produce images with different stylistic characteristics.
4. (Optional|Important) Adjust the `image_denoise` parameter (range 0.0-1.0) to control how much the original image is modified:
   - Values closer to 0.0 make the generated image more similar to the input reference image (at 0.0, it's basically identical to the original)
   - Values closer to 1.0 make the generated image more like pure text-to-image generation (at 1.0, it's as if no reference image was provided)
5. (Optional) Edit the `String(Multiline)` to modify negative prompts, specifying elements you don't want to appear in the generated image.
6. Click the `Run` button or use the shortcut `Ctrl(cmd) + Enter` to execute the image generation.
8. After the API returns results, you can view the generated image in the `Save Image` node. The image will also be saved to the `ComfyUI/output/` directory.

### 3. Additional Notes

The image below shows a comparison of results with and without input image using the same parameter settings:

![Stability AI Stable Diffusion 3.5 With/Without Image Input Comparison](/images/tutorial/api_nodes/stability_ai/stable_diffusion_3_5_compare.jpg)

**Image Denoise**: This parameter determines how much of the original image's features are preserved during generation. It's the most crucial adjustment parameter in image-to-image mode. The image below shows the effects of different denoising strengths:

![Stability AI Stable Diffusion 3.5 Image-to-Image Denoise Strength Explanation](/images/tutorial/api_nodes/stability_ai/stable_diffusion_3_5_image_i2i_image_denoise.jpg)

- **Reference Image Selection**: Choosing images with clear subjects and good composition usually yields better results.
- **Prompt Tips**: In image-to-image mode, prompts should focus more on elements you want to change or enhance, rather than describing everything already present in the image.
- **Mode Switching**: When an input image is provided, the node automatically switches from text-to-image mode to image-to-image mode, and aspect ratio parameters are ignored.

## Related Node Details

You can refer to the documentation below to understand detailed parameter settings for the corresponding node

<Card title="Stability Stable Diffusion 3.5 Image Node Documentation" icon="book" href="/built-in-nodes/api-node/image/stability-ai/stability-ai-stable-diffusion-3-5-image">
Stability Stable Diffusion 3.5 Image API Node Documentation
</Card>