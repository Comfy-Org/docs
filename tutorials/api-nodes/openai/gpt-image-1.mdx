---
title: "OpenAI GPT-Image-1 Node"
description: "Learn how to use the OpenAI GPT-Image-1 API node to generate images in ComfyUI"
sidebarTitle: "GPT-Image-1"
icon: "image"
---

import Faq from "/snippets/tutorials/api-nodes/faq.mdx";
import ReqHint from "/snippets/tutorials/api-nodes/req-hint.mdx";
import UpdateReminder from "/snippets/tutorials/update-reminder.mdx";

![OpenAI GPT-Image-1 Node Screenshot](/images/comfy_core/api_nodes/openai-gpt-image-1.jpg)

OpenAI GPT-Image-1 is part of the ComfyUI API nodes series that allows users to generate images through OpenAI's **GPT-Image-1** model. This is the same model used for image generation in ChatGPT 4o.

This node supports:
- Text-to-image generation
- Image editing functionality (inpainting through masks)

## Node Overview

The **OpenAI GPT-Image-1** node synchronously generates images through OpenAI's image generation API. It receives text prompts and returns images matching the description. GPT-Image-1 is OpenAI's most advanced image generation model currently available, capable of creating highly detailed and realistic images.

<ReqHint/>
<UpdateReminder/>

## Parameter Description

### Required Parameters

| Parameter | Type | Description                                                   |
|-----------|------|---------------------------------------------------------------|
| `prompt`  | Text | Text prompt describing the image content you want to generate |

### Widget Parameters

| Parameter    | Type    | Options                               | Default | Description                                             |
|--------------|---------|---------------------------------------|---------|---------------------------------------------------------|
| `seed`       | Integer | 0-2147483647                          | 0       | Random seed used to control generation results          |
| `quality`    | Option  | low, medium, high                     | low     | Image quality setting, affects cost and generation time |
| `background` | Option  | opaque, transparent                   | opaque  | Whether the returned image has a background             |
| `size`       | Option  | auto, 1024x1024, 1024x1536, 1536x1024 | auto    | Size of the generated image                             |
| `n`          | Integer | 1-8                                   | 1       | Number of images to generate                            |

### Optional Parameters

| Parameter | Type  | Options         | Default | Description                                                 |
|-----------|-------|-----------------|---------|-------------------------------------------------------------|
| `image`   | Image | Any image input | None    | Optional reference image for image editing                  |
| `mask`    | Mask  | Mask input      | None    | Optional mask for inpainting (white areas will be replaced) |

## Usage Examples

### Text-to-Image Example

The image below contains a simple text-to-image workflow. Please download the image and drag it into ComfyUI to load the corresponding workflow.
![ComfyUI openai-gpt-image-1 workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/GPT-Image-1/text2image.png)

The corresponding workflow is very simple:
![ComfyUI openai-gpt-image-1 workflow example](/images/tutorial/api_nodes/openai/gpt-image-1/text2image.jpg)

You only need to load the `OpenAI GPT-Image-1` node, input the description of the image you want to generate in the `prompt` node, connect a `Save Image` node, and then run the workflow.

### Image-to-Image Example

The image below contains a simple image-to-image workflow. Please download the image and drag it into ComfyUI to load the corresponding workflow.
![ComfyUI openai-gpt-image-1 workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/GPT-Image-1/image2image.png)

We will use the image below as input:
![ComfyUI openai-gpt-image-1 workflow input](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/GPT-Image-1/input.webp)

In this workflow, we use the `OpenAI GPT-Image-1` node to generate images and the `Load Image` node to load the input image, then connect it to the `image` input of the `OpenAI GPT-Image-1` node.

![ComfyUI openai-gpt-image-1 workflow example](/images/tutorial/api_nodes/openai/gpt-image-1/image2image.jpg)

### Multiple Image Input Example
Please download the image below and drag it into ComfyUI to load the corresponding workflow.

![Multiple Image Input Example](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/GPT-Image-1/multiple_image_input.png)

Use the hat image below as an additional input image.
![Hat](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/GPT-Image-1/hat.webp)

The corresponding workflow is shown in the image below:
![Multiple Image Input Example](/images/tutorial/api_nodes/openai/gpt-image-1/multi_images_input.png)

The `Batch Images` node is used to load multiple images into the `OpenAI GPT-Image-1` node.

### Inpainting Workflow

GPT-Image-1 also supports image editing functionality, allowing you to specify areas to replace using a mask. Below is a simple inpainting workflow example:

Download the image below and drag it into ComfyUI to load the corresponding workflow. We will continue to use the input image from the image-to-image workflow section.

![ComfyUI openai-gpt-image-1 workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/GPT-Image-1/inpaint.png)

The corresponding workflow is shown in the image
![ComfyUI openai-gpt-image-1 workflow example](/images/tutorial/api_nodes/openai/gpt-image-1/inpaint.jpg)

Compared to the image-to-image workflow, we use the MaskEditor in the `Load Image` node through the right-click menu to draw a mask, then connect it to the `mask` input of the `OpenAI GPT-Image-1` node to complete the workflow.

**Notes**

- The mask and image must be the same size
- When inputting large images, the node will automatically resize the image to an appropriate size

## FAQs

<Faq/>