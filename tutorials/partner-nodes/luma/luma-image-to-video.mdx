---
title: "Luma Image to Video API Node ComfyUI Official Example"
description: "Learn how to use the Luma Image to Video Partner node in ComfyUI"
sidebarTitle: "Luma Image to Video"
---

import ReqHint from "/snippets/tutorials/partner-nodes/req-hint.mdx";
import UpdateReminder from "/snippets/tutorials/update-reminder.mdx";

The [Luma Image to Video](/built-in-nodes/partner-node/video/luma/luma-image-to-video) node allows you to convert static images into smooth, dynamic videos using Luma AI's advanced technology, bringing life and motion to your images.

In this guide, we'll show you how to set up a workflow for image-to-video conversion using this node.

<ReqHint/>
<UpdateReminder/>

## Luma Image to Video Node Documentation

Check out the following documentation to learn more about the node's parameters:

<Card title="Luma Image to Video Node Docs" icon="book" href="/built-in-nodes/partner-node/video/luma/luma-image-to-video">
Luma Image to Video Partner node documentation
</Card>

<Card title="Luma Concepts Node Docs" icon="book" href="/built-in-nodes/partner-node/video/luma/luma-concepts">
Luma Concepts Partner node documentation
</Card>

## Image to Video Workflow with Luma API Node

The Luma Image to Video node requires at least one image input (`first_image` or `last_image`) along with text prompts to determine the video's motion effects. In this guide, we've created an example using `first_image` and `luma_concepts` to showcase Luma AI's video generation capabilities.

### 1. Download the Workflow

The workflow information is included in the metadata of the video below. Download and drag it into ComfyUI to load the workflow.

![Luma Image to Video Workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/luma/i2v/luma_i2v.mp4)

Download the following image to use as input:

![Input Image](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/luma/i2v/input.png)

### 2. Follow the Workflow Steps

![Luma Image to Video Workflow Steps](/images/tutorial/api_nodes/luma/luma_i2v_step_guide.jpg)

Follow these basic steps to run the workflow:
1. Upload your input image in the `first_image` node
2. (Optional) Write prompts in the Luma Image to Video node to describe how you want the image animated
3. (Optional) Modify the `Luma Concepts` node to control camera movement for professional cinematography
4. Click `Run` or use `Ctrl(cmd) + Enter` to generate the video
5. Once the API returns results, view the generated video in the `Save Video` node. The video will also be saved to the `ComfyUI/output/` directory

### 3. Additional Notes

- **Image Input Requirements**: At least one of `first_image` or `last_image` is required, with a maximum of 1 image per input
- **Luma Concepts**: Controls camera movement for professional video effects
- **Seed Parameter**: Only determines if the node should rerun, doesn't affect generation results
- **Enable Input Nodes**: Right-click on purple "Bypass" mode nodes and set "mode" to "always" to enable inputs
- **Model Selection**: Different video generation models have unique characteristics, adjustable via the model parameter
- **Resolution and Duration**: Adjust output video resolution and length using resolution and duration parameters