---
title: "OpenAI DALL·E 2 Node"
description: "Learn how to use the OpenAI DALL·E 2 Partner node to generate images in ComfyUI"
sidebarTitle: "DALL·E 2"
icon: "image"
---

import Faq from "/snippets/tutorials/partner-nodes/faq.mdx";
import ReqHint from "/snippets/tutorials/partner-nodes/req-hint.mdx";
import UpdateReminder from "/snippets/tutorials/update-reminder.mdx";

![OpenAI DALL·E 2 node screenshot](/images/comfy_core/api_nodes/openai-dall-e-2.jpg)

OpenAI DALL·E 2 is part of the ComfyUI Partner Nodes series, allowing users to generate images through OpenAI's **DALL·E 2** model.

This node supports:
- Text-to-image generation
- Image editing functionality (inpainting through masks)

## Node Overview

The **OpenAI DALL·E 2** node generates images synchronously through OpenAI's image generation API. It receives text prompts and returns images that match the description.

<ReqHint/>
<UpdateReminder/>

## Parameter Description

### Required Parameters

| Parameter | Description                                                   |
|-----------|---------------------------------------------------------------|
| `prompt`  | Text prompt describing the image content you want to generate |

### Widget Parameters

| Parameter | Description                                                                | Options/Range                     | Default Value |
|-----------|----------------------------------------------------------------------------|-----------------------------------|---------------|
| `seed`    | Seed value for image generation (currently not implemented in the backend) | 0 to 2^31-1                       | 0             |
| `size`    | Output image dimensions                                                    | "256x256", "512x512", "1024x1024" | "1024x1024"   |
| `n`       | Number of images to generate                                               | 1 to 8                            | 1             |

### Optional Parameters

| Parameter | Description                                                                | Options/Range                     | Default Value |
|-----------|----------------------------------------------------------------------------|-----------------------------------|---------------|
| `image`   | Optional reference image for image editing                                 | Any image input                   | None          |
| `mask`    | Optional mask for local inpainting                                         | Mask input                        | None          |

## Usage Method

## Workflow Examples

This Partner node currently supports two workflows:

- Text to Image
- Inpainting

<Note>
Image to Image workflow is not supported
</Note>

### Text to Image Example

The image below contains a simple text-to-image workflow. Please download the corresponding image and drag it into ComfyUI to load the workflow.
![ComfyUI openai-dall-e-2 workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/openai-dall-e-2/text2image.png)

The corresponding example is very simple
![ComfyUI openai-dall-e-2 workflow example](/images/tutorial/api_nodes/openai/openai-dall-e-2/text2image.jpg)

You only need to load the `OpenAI DALL·E 2` node, input the description of the image you want to generate in the `prompt` node, connect a `Save Image` node, and then run the workflow.

### Inpainting Workflow

DALL·E 2 supports image editing functionality, allowing you to use a mask to specify the area to be replaced. Below is a simple inpainting workflow example:

#### 1. Workflow File Download

Download the image below and drag it into ComfyUI to load the corresponding workflow.

![ComfyUI openai-dall-e-2 workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/openai-dall-e-2/inpainting.png)

We will use the image below as input:
![ComfyUI openai-dall-e-2 workflow input](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/openai-dall-e-2/input.jpg)

#### 2. Workflow File Usage Instructions

![ComfyUI openai-dall-e-2 workflow example](/images/tutorial/api_nodes/openai/openai-dall-e-2/inpainting.jpg)

Since this workflow is relatively simple, if you want to manually implement the corresponding workflow yourself, you can follow the steps below:

1. Use the `Load Image` node to load the image
2. Right-click on the load image node and select `MaskEditor`
3. In the mask editor, use the brush to draw the area you want to redraw
4. Connect the loaded image to the `image` input of the **OpenAI DALL·E 2** node
5. Connect the mask to the `mask` input of the **OpenAI DALL·E 2** node
6. Edit the prompt in the `prompt` node
7. Run the workflow

**Notes**

- If you want to use the image editing functionality, you must provide both an image and a mask (both are required)
- The mask and image must be the same size
- When inputting large images, the node will automatically resize the image to an appropriate size
- The URLs returned by the API are valid for a short period, please save the results promptly
- Each generation consumes credits, charged according to image size and quantity

## FAQs

<Faq/>