---
title: "How to install ComfyUI manually in different systems"
Description: "This section will guide you through the manual installation process on Windows, MacOS and Linux"
icon: "wrench"
sidebarTitle: "Manual Installation"
---

For the installation of ComfyUI, it is mainly divided into several steps:
1. Create a virtual environment(avoid polluting the system-level Python environment)
2. Clone the ComfyUI code repository
3. Install dependencies
4. Start ComfyUI

<Note>
Python 3.13 is very well supported. If you have trouble with some custom node dependencies on 3.13 you can try 3.12.

Python 3.14 will work if you comment out the `kornia` dependency in the requirements.txt file (breaks the canny node) but it is not recommended.
</Note>

You can also refer to [ComfyUI CLI](/comfy-cli/getting-started) to install ComfyUI, it is a command line tool that can easily install ComfyUI and manage its dependencies.

## Create a virtual environment

<Tip>
    Independent virtual environments are necessary because ComfyUI's dependencies may conflict with other dependencies on the system, and it can also avoid polluting the system-level Python environment.
</Tip>

[Install Miniconda](https://docs.anaconda.com/free/miniconda/index.html#latest-miniconda-installer-links). This will help you install the correct versions of Python and other libraries needed by ComfyUI.

Create an environment with Conda.

```
conda create -n comfyenv
conda activate comfyenv
```

## Clone the ComfyUI code repository

You need to ensure that you have installed [Git](https://git-scm.com/downloads) on your system. First, you need to open the terminal (command line), then clone the code repository.
<Tabs>
<Tab title="Windows">
<Warning>If you have not installed Microsoft Visual C++ Redistributable, please install it [here.](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170)</Warning>
</Tab>
<Tab title="Linux">
Open Terminal application.
</Tab>
<Tab title="MacOS">
Open [Terminal application](https://support.apple.com/guide/terminal/open-or-quit-terminal-apd5265185d-f365-44cb-8b09-71a064a42125/mac).
</Tab>
</Tabs>

```bash
git clone git@github.com:comfyanonymous/ComfyUI.git
```

## Install GPU and ComfyUI dependencies

<Steps>
    <Step title="Install GPU dependencies">
    Install GPU Dependencies

<Accordion title="Nvidia">
Nvidia users should install stable pytorch using this command:

```bash
pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu130
```

Alternatively, you can install the nightly version of PyTorch.

<Accordion title="Install Nightly">
<Warning>Install Nightly version (might be more risky)</Warning>

This is the command to install pytorch nightly instead which might have performance improvements:

```bash
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130
```
</Accordion>

<Accordion title="Troubleshooting">
If you get the "Torch not compiled with CUDA enabled" error, uninstall torch with:

```bash
pip uninstall torch
```

And install it again with the command above.
</Accordion>
</Accordion>
<Accordion title="AMD (Linux)">
AMD users can install rocm and pytorch with pip if you don't have it already installed, this is the command to install the stable version:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.4
```

Alternatively, you can install the nightly version of PyTorch.

<Accordion title="Install Nightly">
<Warning>Install Nightly version (might be more risky)</Warning>

This is the command to install the nightly with ROCm 7.0 which might have some performance improvements:

```bash
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm7.0
```
</Accordion>
</Accordion>
<Accordion title="AMD Experimental (Windows and Linux)">
<Warning>
Experimental support for Windows and Linux. RDNA 3, 3.5 and 4 only.

These have less hardware support than the builds above but they work on Windows. You also need to install the pytorch version specific to your hardware.
</Warning>

**RDNA 3 (RX 7000 series):**

```bash
pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx110X-dgpu/
```

**RDNA 3.5 (Strix halo/Ryzen AI Max+ 365):**

```bash
pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx1151/
```

**RDNA 4 (RX 9000 series):**

```bash
pip install --pre torch torchvision torchaudio --index-url https://rocm.nightlies.amd.com/v2/gfx120X-all/
```
</Accordion>
<Accordion title="Intel">
Intel Arc GPU users can install native PyTorch with torch.xpu support using pip. More information can be found [here](https://pytorch.org/docs/main/notes/get_start_xpu.html).

**Option 1: Install PyTorch xpu**

To install PyTorch xpu, use the following command:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu
```

<Accordion title="Install Nightly">
<Warning>Install Nightly version (might be more risky)</Warning>

This is the command to install the Pytorch xpu nightly which might have some performance improvements:

```bash
pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu
```
</Accordion>

**Option 2: Intel Extension for PyTorch (IPEX)**

Alternatively, Intel GPUs supported by Intel Extension for PyTorch (IPEX) can leverage IPEX for improved performance.

Visit [Installation](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=gpu) for more information.
</Accordion>
<Accordion title="Mac ARM Silicon">
You can install ComfyUI in Apple Mac silicon (M1 or M2) with any recent macOS version.

Install pytorch nightly. For instructions, read the [Accelerated PyTorch training on Mac](https://developer.apple.com/metal/pytorch/) Apple Developer guide (make sure to install the latest pytorch nightly).

```bash
conda install pytorch-nightly::pytorch torchvision torchaudio -c pytorch-nightly
```

<Note>
Remember to add your models, VAE, LoRAs etc. to the corresponding Comfy folders (models/checkpoints, models/vae, etc.).
</Note>
</Accordion>
<Accordion title="Ascend NPUs">
For models compatible with Ascend Extension for PyTorch (torch_npu). To get started, ensure your environment meets the prerequisites outlined on the [installation](https://ascend.github.io/docs/sources/ascend/quick_install.html) page.

**Step-by-step guide:**

1. Begin by installing the recommended or newer kernel version for Linux as specified in the Installation page of torch-npu, if necessary.
2. Proceed with the installation of Ascend Basekit, which includes the driver, firmware, and CANN, following the instructions provided for your specific platform.
3. Next, install the necessary packages for torch-npu by adhering to the platform-specific instructions on the [Installation](https://ascend.github.io/docs/sources/pytorch/install.html#pytorch) page.
4. Finally, follow the ComfyUI manual installation guide for Linux. Once all components are installed, you can run ComfyUI as described earlier.
</Accordion>
<Accordion title="Cambricon MLUs">
For models compatible with Cambricon Extension for PyTorch (torch_mlu).

**Step-by-step guide:**

1. Install the Cambricon CNToolkit by adhering to the platform-specific instructions on the [Installation](https://www.cambricon.com/docs/sdk_1.15.0/cntoolkit_3.7.2/cntoolkit_install_3.7.2/index.html)
2. Next, install the PyTorch(torch_mlu) following the instructions on the [Installation](https://www.cambricon.com/docs/sdk_1.15.0/cambricon_pytorch_1.17.0/user_guide_1.9/index.html)
3. Launch ComfyUI by running `python main.py`
</Accordion>
<Accordion title="Iluvatar Corex">
For models compatible with Iluvatar Extension for PyTorch.

**Step-by-step guide:**

1. Install the Iluvatar Corex Toolkit by adhering to the platform-specific instructions on the [Installation](https://support.iluvatar.com/#/DocumentCentre?id=1&nameCenter=2&productId=520117912052801536)
2. Launch ComfyUI by running `python main.py`
</Accordion>
    </Step>
    <Step title="Install ComfyUI dependencies">
    ```bash
cd ComfyUI
pip install -r requirements.txt
```
    </Step>
    <Step title="Start ComfyUI">
    Start the application

```
cd ComfyUI
python main.py
```
    </Step>
</Steps>

## How to update ComfyUI

<Steps>
    <Step title="pull the latest code">
    Use the command line to enter the installation path of ComfyUI, then pull the latest code.
    ```bash
    cd <installation path>/ComfyUI
    git pull
    ```
    </Step>
    <Step title="install the dependencies">
    Use the command line to enter the installation path of ComfyUI, then install the dependencies.
    <Warning>
    You need to ensure that the current Python environment is the ComfyUI virtual environment, otherwise the dependencies will be installed to the system-level Python environment, polluting the system-level Python environment.
    </Warning>
    ```bash
        pip install -r requirements.txt
    ```
    </Step>
</Steps>

## Adding Extra Model Paths

If you want to manage your model files outside of `ComfyUI/models`, you may have the following reasons:

- You have multiple ComfyUI instances and want them to share model files to save disk space
- You have different types of GUI programs (such as WebUI) and want them to use the same model files
- Model files cannot be recognized or found

We provide a way to add extra model search paths via the `extra_model_paths.yaml` configuration file

### Open Config File

<Tabs>
  <Tab title="Portable/Manual Install">
  For the ComfyUI version such as [portable](/installation/comfyui_portable_windows) and [manual](/installation/manual_install), you can find an example file named `extra_model_paths.yaml.example` in the root directory of ComfyUI:
  ```
  ComfyUI/extra_model_paths.yaml.example
  ```

  Copy and rename it to `extra_model_paths.yaml` for use. Keep it in ComfyUI's root directory at `ComfyUI/extra_model_paths.yaml`.
  You can also find the config example file [here](https://github.com/comfyanonymous/ComfyUI/blob/master/extra_model_paths.yaml.example)
  
  </Tab>
  <Tab title="ComfyUI Desktop">
  If you are using the [ComfyUI Desktop](/installation/desktop/windows) application, you can follow the image below to open the extra model config file:

  ![Open Config File](/images/desktop/extra_model_paths.jpg)

  Or open it directly at:

  <Tabs>
    <Tab title="Windows">
      ```
      C:\Users\YourUsername\AppData\Roaming\ComfyUI\extra_models_config.yaml
      ```
    </Tab>
    <Tab title="macOS">
      ```
      ~/Library/Application Support/ComfyUI/extra_models_config.yaml
      ```
    </Tab>
  </Tabs>

  You should keep the file in the same directory, should not move these files to other places.
  </Tab>
</Tabs>

If the file does not exist, you can create it yourself with any text editor.

### Example Structure

Suppose you want to add the following model paths to ComfyUI:

```
üìÅ YOUR_PATH/
  ‚îú‚îÄ‚îÄ üìÅmodels/
  |   ‚îú‚îÄ‚îÄ üìÅ lora/
  |   ‚îÇ   ‚îî‚îÄ‚îÄ xxxxx.safetensors
  |   ‚îú‚îÄ‚îÄ üìÅ checkpoints/
  |   ‚îÇ   ‚îî‚îÄ‚îÄ xxxxx.safetensors
  |   ‚îú‚îÄ‚îÄ üìÅ vae/
  |   ‚îÇ   ‚îî‚îÄ‚îÄ xxxxx.safetensors
  |   ‚îî‚îÄ‚îÄ üìÅ controlnet/
  |       ‚îî‚îÄ‚îÄ xxxxx.safetensors
```

Then you can configure the `extra_model_paths.yaml` file like below to let ComfyUI recognize the model paths on your device:

```
my_custom_config:
    base_path: YOUR_PATH
    loras: models/loras/
    checkpoints: models/checkpoints/
    vae: models/vae/
    controlnet: models/controlnet/
```
or

```
my_custom_config:
    base_path: YOUR_PATH/models/
    loras: loras
    checkpoints: checkpoints
    vae: vae
    controlnet: controlnet
```

<Warning>
  For the desktop version, please add the configuration to the existing configuration path without overwriting the path configuration generated during installation. Please back up the corresponding file before modification, so that you can restore it when you make a mistake.
</Warning>

Or you can refer to the default [extra_model_paths.yaml.example](https://github.com/comfyanonymous/ComfyUI/blob/master/extra_model_paths.yaml.example) for more configuration options. After saving, you need to **restart ComfyUI** for the changes to take effect.

Below is the original config example:

```yaml
#Rename this to extra_model_paths.yaml and ComfyUI will load it


#config for a1111 ui
#all you have to do is change the base_path to where yours is installed
a111:
    base_path: path/to/stable-diffusion-webui/

    checkpoints: models/Stable-diffusion
    configs: models/Stable-diffusion
    vae: models/VAE
    loras: |
         models/Lora
         models/LyCORIS
    upscale_models: |
                  models/ESRGAN
                  models/RealESRGAN
                  models/SwinIR
    embeddings: embeddings
    hypernetworks: models/hypernetworks
    controlnet: models/ControlNet

#config for comfyui
#your base path should be either an existing comfy install or a central folder where you store all of your models, loras, etc.

#comfyui:
#     base_path: path/to/comfyui/
#     # You can use is_default to mark that these folders should be listed first, and used as the default dirs for eg downloads
#     #is_default: true
#     checkpoints: models/checkpoints/
#     clip: models/clip/
#     clip_vision: models/clip_vision/
#     configs: models/configs/
#     controlnet: models/controlnet/
#     diffusion_models: |
#                  models/diffusion_models
#                  models/unet
#     embeddings: models/embeddings/
#     loras: models/loras/
#     upscale_models: models/upscale_models/
#     vae: models/vae/

#other_ui:
#    base_path: path/to/ui
#    checkpoints: models/checkpoints
#    gligen: models/gligen
#    custom_nodes: path/custom_nodes

```

For example, if your WebUI is located at `D:\stable-diffusion-webui\`, you can modify the corresponding configuration to
```yaml
a111:
    base_path: D:\stable-diffusion-webui\
    checkpoints: models/Stable-diffusion
    configs: models/Stable-diffusion
    vae: models/VAE
    loras: |
         models/Lora
         models/LyCORIS
    upscale_models: |
                  models/ESRGAN
                  models/RealESRGAN
                  models/SwinIR
    embeddings: embeddings
    hypernetworks: models/hypernetworks
    controlnet: models/ControlNet
```

### Add Extra Custom Nodes Path

Besides adding external models, you can also add custom nodes paths that are not in the default path of ComfyUI

<Tip>
  Please note that this will not change the default installation path of custom nodes, but will add an extra path search when starting ComfyUI. You still need to complete the installation of custom node dependencies in the corresponding environment to ensure the integrity of the running environment.
</Tip>

Below is a simple configuration example (MacOS), please modify it according to your actual situation and add it to the corresponding configuration file, save it and restart ComfyUI for the changes to take effect:

```yaml
my_custom_nodes:
  custom_nodes: /Users/your_username/Documents/extra_custom_nodes
```
