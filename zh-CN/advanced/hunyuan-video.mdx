---
title: "ComfyUI 混元视频示例"
description: "本文介绍了如何在 ComfyUI 中完成混元文生视频及图生视频的工作流"
sidebarTitle: "混元视频"
---

> 视频来自[腾讯](https://huggingface.co/tencent)

混元视频（Hunyuan Video）系列是是[腾讯](https://huggingface.co/tencent)研发并开源的，该模型以混合架构为核心，支持[文本生成视频](https://github.com/Tencent/HunyuanVideo) 
和[图生成视频](https://github.com/Tencent/HunyuanVideo-I2V)。

该模型采用「双流到单流」Transformer架构，高效融合文本、图像和运动信息，提升视频帧间一致性、画质和内容对齐度。

本篇指南将引导你完成在 ComfyUI 中对应的模型安装，以及文生视频和图生视频的工作流。

<Tip>
本篇教程中的工作流图片的 Metadata 中已包含对应模型下载信息，直接拖入 ComfyUI 或使用菜单 `Workflows` -> `Open（ctrl+o）` 来加载对应的工作流，会提示完成对应的模型下载。
另外在本篇指南中也提供了对应的模型地址 ，如果自动下载无法完成，请尝试手动完成模型的下载。所有模型保存在[这里](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files)可以下载
</Tip>

## 工作流共用模型

在文生视频和图生视频的工作流中下面的这些模型是共有的，请完成下载并保存到指定目录中

- [clip_l.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/text_encoders/clip_l.safetensors?download=true)
- [llava_llama3_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/text_encoders/llava_llama3_fp8_scaled.safetensors?download=true)
- [hunyuan_video_vae_bf16.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/vae/hunyuan_video_vae_bf16.safetensors?download=true)

保存位置：

```
ComfyUI/
├── models/
│   ├── text_encoders/
│   │   ├── clip_l.safetensors
│   │   └── llava_llama3_fp8_scaled.safetensors
│   ├── vae/
│   │   └── hunyuan_video_vae_bf16.safetensors
```

## 混元文生视频工作流

简介：
- 更新于 2024 年 12 月
- 基于 LLaVA 架构，支持文本生成视频
- 参数规模：13B
- 单次生成视频时长可带 5 秒
- 支持 1080p 视频生成

### 1. 文生视频相关工作流

请保存下面的图片，并拖入 ComfyUI 以加载工作流
- 工作流图片

### 2. 混元文生图模型

请下载 [hunyuan_video_t2v_720p_bf16.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/diffusion_models/hunyuan_video_t2v_720p_bf16.safetensors?download=true) 并保存至 `ComfyUI/models/diffusion_models` 文件夹中

确保包括共用模型文件夹有以下完整的模型文件：

```
ComfyUI/
├── models/
│   ├── text_encoders/
│   │   ├── clip_l.safetensors                       // 共用模型
│   │   └── llava_llama3_fp8_scaled.safetensors      // 共用模型
│   ├── vae/
│   │   └── hunyuan_video_vae_bf16.safetensors       // 共用模型
│   └── diffusion_models/
│       └── hunyuan_video_t2v_720p_bf16.safetensors  // T2V 模型
```

### 3. 按步骤完成工作流的运行

![ComfyUI 混元视频T2V 工作流](/images/tutorial/advanced/hunyuanvideo/flow_diagram_t2v.jpg)

1. 确保在`DualCLIPLoader`中下面的模型已加载：
   - clip_name1: clip_l.safetensors
   - clip_name2: llava_llama3_fp8_scaled.safetensors
2. 确保在`Load Diffusion Model`加载了`diffusion_model_name: hunyuan_video_t2v_720p_bf16.safetensors`
3. 确保在`Load VAE`中加载了`vae_name: hunyuan_video_vae_bf16.safetensors`
4. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流

## 混元图生视频工作流

简介：
- 更新于 2025 年 3 月
- 基于 HunyuanVideo 框架，能将静态图像转化为流畅的高质量视频
- 支持 1080p 视频生成
- 参数规模：13B
- 同时开放了 LoRA 训练代码，支持定制特殊视频效果如：头发生长、物体变形等等
目前混元图生视频模型分为两个版本：
 - v1 “concat” : 视频的运动流畅性较好，但比较少遵循图像引导
 - v2 “replace”: 在v1 更新后的次日更新的版本，图像的引导性较好，但相对于 V1 版本似乎不那么有活力



![HunyuanVideo v1](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/hunyuan_video_image_to_video.webp) 
![HunyuanVideo v2](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/hunyuan_video_image_to_video_v2.webp) 

### v1 及 v2 版本共用的模型

请下载下面的文件，并保存到 `ComfyUI/models/clip_vision` 目录中
- [llava_llama3_vision.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/clip_vision/llava_llama3_vision.safetensors?download=true)

### v1 “concat” 图生视频工作流

#### 1. 工作流及相关素材

请下载下面的工作流图片,并拖入 ComfyUI 以加载工作流
【工作流图片】

请下载下面的图片，我们将使用它作为图生视频的起始帧
![起始帧](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/hunyuan-video/i2v/robot-ballet.png)

#### 2. v1 版本模型

- [hunyuan_video_image_to_video_720p_bf16.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/diffusion_models/hunyuan_video_image_to_video_720p_bf16.safetensors?download=true)

确保包括共用模型文件夹有以下完整的模型文件：

```
ComfyUI/
├── models/
│   ├── clip_vision/
│   │   └── llava_llama3_vision.safetensors                     // I2V 共用模型
│   ├── text_encoders/
│   │   ├── clip_l.safetensors                                  //  共用模型
│   │   └── llava_llama3_fp8_scaled.safetensors                 //  共用模型
│   ├── vae/
│   │   └── hunyuan_video_vae_bf16.safetensors                  // 共用模型
│   └── diffusion_models/
│       └── hunyuan_video_image_to_video_720p_bf16.safetensors  // I2V v1 "concat" 版本模型
```

#### 3. 按步骤完成工作流

![ComfyUI 混元视频I2V v1 工作流](/images/tutorial/advanced/hunyuanvideo/flow_diagram_i2v_v1.jpg)

1. 确保 `DualCLIPLoader` 中下面的模型已加载：
   - clip_name1: clip_l.safetensors
   - clip_name2: llava_llama3_fp8_scaled.safetensors
2. 确保  `Load CLIP Vision` 加载了 `llava_llama3_vision.safetensors`
3. 请在 `Load Image Model` 加载了 `hunyuan_video_image_to_video_720p_bf16.safetensors`
4. 确保 `Load VAE` 中加载了 `hunyuan_video_vae_bf16.safetensors`
5. 确保 `Load Diffusion Model` 中加载了 `hunyuan_video_image_to_video_720p_bf16.safetensors`
6. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流

### v2 “replace” 图生视频工作流

v2 版本的工作流与 v1 版本的工作流基本相同，你只需要下载一个 replace 的模型，然后在 `Load Diffusion Model` 中使用。

#### 1. 工作流及相关素材

请下载下面的工作流图片,并拖入 ComfyUI 以加载工作流

- 工作流图片

请下载下面的图片，我们将使用它作为图生视频的起始帧
![起始帧](https://comfyanonymous.github.io/ComfyUI_examples/flux/flux_dev_example.png)

#### 2. v2 版本模型

- [hunyuan_video_v2_replace_image_to_video_720p_bf16.safetensors](https://huggingface.co/Comfy-Org/HunyuanVideo_repackaged/resolve/main/split_files/diffusion_models/hunyuan_video_v2_replace_image_to_video_720p_bf16.safetensors?download=true)

确保包括共用模型文件夹有以下完整的模型文件：

```
ComfyUI/
├── models/
│   ├── clip_vision/
│   │   └── llava_llama3_vision.safetensors                                // I2V 共用模型
│   ├── text_encoders/
│   │   ├── clip_l.safetensors                                             //  共用模型
│   │   └── llava_llama3_fp8_scaled.safetensors                            //  共用模型
│   ├── vae/
│   │   └── hunyuan_video_vae_bf16.safetensors                             //  共用模型
│   └── diffusion_models/
│       └── hunyuan_video_v2_replace_image_to_video_720p_bf16.safetensors  // V2 "replace" 版本模型
```

#### 3. 按步骤完成工作流

![ComfyUI 混元视频I2V v2 工作流](/images/tutorial/advanced/hunyuanvideo/flow_diagram_i2v_v2.jpg)

1. 确保 `DualCLIPLoader` 中下面的模型已加载：
   - clip_name1: clip_l.safetensors
   - clip_name2: llava_llama3_fp8_scaled.safetensors
2. 确保 `Load CLIP Vision` 加载了 `llava_llama3_vision.safetensors`
3. 请在 `Load Image Model` 加载了 `hunyuan_video_image_to_video_720p_bf16.safetensors`
4. 确保 `Load VAE` 中加载了 `hunyuan_video_vae_bf16.safetensors`
5. 确保 `Load Diffusion Model` 中加载了 `hunyuan_video_v2_replace_image_to_video_720p_bf16.safetensors`
6. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流