---
title: "ComfyUI Wan2.1 VACE 视频示例"
description: "本文介绍了如何在 ComfyUI 中完成 Wan2.1 VACE 视频生成示例"
sidebarTitle: "Wan2.1 VACE"
---

VACE 14B 是阿里通义万相团队推出的开源视频编辑统一模型。该模型通过整合多任务能力、支持高分辨率处理及灵活的多模态输入机制，显著提升了视频创作的效率与质量。

该模型基于 [Apache-2.0](https://github.com/ali-vilab/VACE?tab=Apache-2.0-1-ov-file) 协议开源，可用于个人商业用途。

以下是其核心特性与技术亮点的综合分析：

- 多模态输入:支持文本、图像、视频、遮罩、控制信号等多种输入形式
- 统一架构:单一模型支持多种任务,可自由组合功能
- 动作迁移:基于参考视频生成连贯动作
- 局部替换:通过遮罩替换视频中的特定区域
- 视频扩展:补全动作或扩展背景
- 背景替换:保留主体更换环境背景


目前 VACE 发布了 1.3B 和 14B 两个版本，14B 版本相比 1.3B 版本，支持 720P 分辨率输出,画面细节和稳定性更好。

| 模型                                                         | 480P | 720P |
| ------------------------------------------------------------ | ---- | ---- |
| [VACE-1.3B](https://huggingface.co/Wan-AI/Wan2.1-VACE-1.3B) | ✅   | ❌   |
| [VACE-14B](https://huggingface.co/Wan-AI/Wan2.1-VACE-14B)   | ✅   | ✅   |

相关模型权重和代码仓库：

- [VACE-1.3B](https://huggingface.co/Wan-AI/Wan2.1-VACE-1.3B)
- [VACE-14B](https://huggingface.co/Wan-AI/Wan2.1-VACE-14B)
- [Github](https://github.com/ali-vilab/VACE)
- [VACE 项目主页](https://ali-vilab.github.io/VACE-Page/)

### 模型安装

**diffusion_models** 
[wan2.1_vace_14B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_vace_14B_fp16.safetensors)

<Tip>
如果你之前运行过 Wan Video 相关的工作流，你可能已经有了下面的这些文件。
</Tip>

**VAE**
- [wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors?download=true)

从**Text encoders** 选择一个版本进行下载，
- [umt5_xxl_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp16.safetensors?download=true)
- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors?download=true)


文件保存位置
```
ComfyUI/
├── models/
│   ├── diffusion_models/
│   │   └─── wan2.1_vace_14B_fp16.safetensors
│   ├── text_encoders/
│   │   └─── umt5_xxl_fp8_e4m3fn_scaled.safetensors # 或者 fp16 版本
│   └── vae/
│       └──  wan_2.1_vae.safetensors
```

## 工作流

### 1. 工作流下载 

### 2. 按步骤完成工作流的运行

![]()
1. 确保 `Load Diffusion Model` 节点加载了 `wan2.1_flf2v_720p_14B_fp16.safetensors` 或者 `wan2.1_flf2v_720p_14B_fp8_e4m3fn.safetensors`
2. 确保 `Load CLIP` 节点加载了 `umt5_xxl_fp8_e4m3fn_scaled.safetensors`
3. 确保 `Load VAE` 节点加载了 `wan_2.1_vae.safetensors`
4. 确保 `Load CLIP Vision` 节点加载了 `clip_vision_h.safetensors `
5. 在 `Start_image` 节点上传起始帧
6. 在 `End_image` 节点上传结束帧
7. （可选）修改 正向和负向的提示词（Prompt）使用中英文都可以
8. （**重要**）在 `WanFirstLastFrameToVideo` 修改对应视频的尺寸我们默认使用了 720 * 1280 的尺寸来，因为这是一个 720P 的尺寸来，因为这是一个720P的模型，所以使用较小的尺寸会无法获得较好的结果。
9. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频生成



