---
title: "Wan2.2 视频生成ComfyUI 官方原生工作流示例"
description: "阿里云通义万相2.2视频生成模型在ComfyUI中的官方使用指南"
sidebarTitle: Wan2.2
---

import UpdateReminder from '/snippets/zh/tutorials/update-reminder.mdx'

<iframe
  className="w-full aspect-video rounded-xl"
  src="//player.bilibili.com/player.html?isOutside=true&aid=114930791549176&bvid=BV1gk8EzaEGt&cid=31337744098&p=1"
  title="ComfyUI Selection Toolbox New Features"
  allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

通义万相 2.2（Wan 2.2）是阿里云推出的新一代多模态生成模型。该模型采用创新的 MoE（Mixture of Experts）架构，由高噪专家模型和低噪专家模型组成，能够根据去噪时间步进行专家模型划分，从而生成更高质量的视频内容。

Wan 2.2 具备三大核心特性：影视级美学控制，深度融合专业电影工业的美学标准，支持光影、色彩、构图等多维度视觉控制；大规模复杂运动，轻松还原各类复杂运动并强化运动的流畅度和可控性；精准语义遵循，在复杂场景和多对象生成方面表现卓越，更好还原用户的创意意图。
模型支持文生视频、图生视频等多种生成模式，适用于内容创作、艺术创作、教育培训等多种应用场景。

## 模型亮点

- **影视级美学控制**：专业镜头语言，支持光影、色彩、构图等多维度视觉控制
- **大规模复杂运动**：流畅还原各类复杂运动，强化运动可控性和自然度
- **精准语义遵循**：复杂场景理解，多对象生成，更好还原创意意图
- **高效压缩技术**：5B版本高压缩比VAE，显存优化，支持混合训练

## Wan2.2 开源模型版本

Wan2.2 系列模型基于 Apache2.0 开源协议，支持商业使用。Apache2.0 许可证允许您自由使用、修改和分发这些模型，包括商业用途，只需保留原始版权声明和许可证文本。

| 模型类型 | 模型名称 | 参数量 | 主要功能 | 模型仓库 |
|---------|---------|--------|----------|----------|
| 混合模型 | Wan2.2-TI2V-5B | 5B | 支持文本生成视频和图像生成视频的混合版本，单一模型满足两大核心任务需求 | 🤗 [Wan2.2-TI2V-5B](https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B) |
| 图生视频 | Wan2.2-I2V-A14B | 14B | 将静态图像转换为动态视频，保持内容一致性和流畅的动态过程 | 🤗 [Wan2.2-I2V-A14B](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B) |
| 文生视频 | Wan2.2-T2V-A14B | 14B | 从文本描述生成高质量视频，具备影视级美学控制和精准语义遵循 | 🤗 [Wan2.2-T2V-A14B](https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B) |

本篇教程将使用 [🤗 Comfy-Org/Wan_2.2_ComfyUI_Repackaged](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged)的版本进行

<UpdateReminder/>

![Wan2.2 template](/images/tutorial/video/wan/wan2_2/template.jpg)

## Wan2.2 TI2V 5B 混合版本工作流示例

<Tip>
Wan2.2 5B 版本配合 ComfyUI 原生 offloading功能，能很好地适配 8GB 显存。
</Tip>
### 1. 工作流文件下载

请更新你的 ComfyUI 到最新版本，并通过菜单 `工作流` -> `浏览模板` -> `视频` 找到 “Wan2.2 5B video generation” 以加载工作流

<video
  controls
  className="w-full aspect-video"
  src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/ati/wan_ati.mp4"
></video>

### 2. 手动下载模型

**Diffusion Model**
- [wan2.2_ti2v_5B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_ti2v_5B_fp16.safetensors)

**VAE**
- [wan2.2_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan2.2_vae.safetensors)

**Text Encoder**   
- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)

```
ComfyUI/
├───📂 models/
│   ├───📂 diffusion_models/
│   │   └───wan2.2_ti2v_5B_fp16.safetensors
│   ├───📂 text_encoders/
│   │   └─── umt5_xxl_fp8_e4m3fn_scaled.safetensors 
│   └───📂 vae/
│       └── wan2.2_vae.safetensors
```

### 3. 按步骤完成工作流
![步骤图](/images/tutorial/video/wan/wan2_2/wan_2.2_5b_t2v.jpg)

1. 确保`Load Diffusion Model`节点加载了 `wan2.2_ti2v_5B_fp16.safetensors` 模型
2. 确保`Load CLIP`节点加载了 `umt5_xxl_fp8_e4m3fn_scaled.safetensors` 模型
3. 确保`Load VAE`节点加载了 `wan2.2_vae.safetensors` 模型
4. （可选）如果你需要进行图生视频，可以使用快捷键 Ctrl+B 来启用 `Load image` 节点来上传图片
5. （可选）在`Wan22ImageToVideoLatent` 你可以进行尺寸的设置调整，和视频总帧数 `length` 调整
6. （可选）如果你需要修改提示词（正向及负向）请在序号`5` 的 `CLIP Text Encoder` 节点中进行修改
7. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频生成

## Wan2.2 14B T2V 文生视频工作流示例

### 1. 工作流文件下载

请更新你的 ComfyUI 到最新版本，并通过菜单  `工作流` -> `浏览模板` -> `视频` 找到 “Wan2.2 14B T2V” 


### 2. 手动下载模型

**Diffusion Model**
- [wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors)
- [wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors)

**VAE**
- [wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors)

**Text Encoder**   
- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)


```
ComfyUI/
├───📂 models/
│   ├───📂 diffusion_models/
│   │   ├─── wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors
│   │   └─── wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors
│   ├───📂 text_encoders/
│   │   └─── umt5_xxl_fp8_e4m3fn_scaled.safetensors 
│   └───📂 vae/
│       └── wan_2.1_vae.safetensors
```


### 3. 按步骤完成工作流
![步骤图](/images/tutorial/video/wan/wan2_2/wan_2.2_5b_t2v.jpg)

1. 确保第一个 `Load Diffusion Model`节点加载了 `wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors` 模型
2. 确保第二个 `Load Diffusion Model`节点加载了 `wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors` 模型
3. 确保`Load CLIP`节点加载了 `umt5_xxl_fp8_e4m3fn_scaled.safetensors` 模型
4. 确保`Load VAE`节点加载了 `wan_2.1_vae.safetensors` 模型
5. （可选）在`EmptyHunyuanLatentVideo` 你可以进行尺寸的设置调整，和视频总帧数 `length` 调整
6. 如果你需要修改提示词（正向及负向）请在序号`6` 的 `CLIP Text Encoder` 节点中进行修改
7. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频生成

## Wan2.2 14B I2V 图生视频工作流示例

### 1. 工作流文件

请更新你的 ComfyUI 到最新版本，并通过菜单  `工作流` -> `浏览模板` -> `视频` 找到 “Wan2.2 14B I2V” 以加载工作流

你可以使用下面的图片作为输入
![输入图片](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/2.2/input.jpg)

### 2. 手动下载模型

**Diffusion Model**
- [wan2.2_i2v_high_noise_14B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp16.safetensors)
- [wan2.2_i2v_low_noise_14B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp16.safetensors)

**VAE**
- [wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors)

**Text Encoder**   
- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)

```
ComfyUI/
├───📂 models/
│   ├───📂 diffusion_models/
│   │   ├─── wan2.2_i2v_low_noise_14B_fp16.safetensors
│   │   └─── wan2.2_i2v_high_noise_14B_fp16.safetensors
│   ├───📂 text_encoders/
│   │   └─── umt5_xxl_fp8_e4m3fn_scaled.safetensors 
│   └───📂 vae/
│       └── wan_2.1_vae.safetensors
```
### 3. 按步骤完成工作流
![步骤图](/images/tutorial/video/wan/wan2_2/wan_2.2_5b_t2v.jpg)

1. 确保第一个 `Load Diffusion Model`节点加载了 `wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors` 模型
2. 确保第二个 `Load Diffusion Model`节点加载了 `wan2.2_t2v_low_noise_14B_fp8_scaled.safetensors` 模型
3. 确保`Load CLIP`节点加载了 `umt5_xxl_fp8_e4m3fn_scaled.safetensors` 模型
4. 确保`Load VAE`节点加载了 `wan_2.1_vae.safetensors` 模型
5. 在 `Load Image` 节点上传作为起始帧的图像
6. 如果你需要修改提示词（正向及负向）请在序号`6` 的 `CLIP Text Encoder` 节点中进行修改
7. 可选）在`EmptyHunyuanLatentVideo` 你可以进行尺寸的设置调整，和视频总帧数 `length` 调整
8. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频生成
