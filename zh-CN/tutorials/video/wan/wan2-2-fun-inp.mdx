---
title: "ComfyUI Wan2.2 Fun Inp 首尾帧视频生成示例"
description: "本文介绍了如何在 ComfyUI 中完成 Wan2.2 Fun Inp 首尾帧视频生成示例"
sidebarTitle: "Wan2.2 Fun Inp"
---

import UpdateReminder from '/snippets/zh/tutorials/update-reminder.mdx'

**Wan2.2-Fun-Inp** 是 Alibaba pai团队推出的首尾帧控制视频生成模型，支持输入**首帧和尾帧图像**，生成中间过渡视频，为创作者带来更强的创意控制力。该模型采用 **Apache 2.0 许可协议**发布，支持商业使用。

**核心功能**：
- **首尾帧控制**：支持输入首帧和尾帧图像，生成中间过渡视频，提升视频连贯性与创意自由度
- **高质量视频生成**：基于 Wan2.2 架构，输出影视级质量视频
- **多分辨率支持**：支持生成512×512、768×768、1024×1024等分辨率的视频，适配不同场景需求

**模型版本**：
- **14B 高性能版**：模型体积达 32GB+，效果更优但需高显存支持

下面是相关模型权重和代码仓库：

- [🤗Wan2.2-Fun-Inp-14B](https://huggingface.co/alibaba-pai/Wan2.2-Fun-A14B-InP)
- 代码仓库：[VideoX-Fun](https://github.com/aigc-apps/VideoX-Fun)

<UpdateReminder/>

## Wan2.2 Fun Inp 首尾帧视频生成工作流示例

这里提供的工作流包含了两个版本的
1. 使用了 lightx2v 的 [Wan2.2-Lightning](https://huggingface.co/lightx2v/Wan2.2-Lightning) 4 步 LoRA 来实现视频生成提速的版本
2. 没有使用加速  LoRA 的 fp8_scaled 版本

下面是使用 RTX4090D 24GB 显存 GPU 测试的结果

| 模型类型                 | 分辨率  | 显存占用 | 首次生成时长 | 第二次生成时长 |
| ------------------------ | ------- | -------- | ------------ | -------------- |
| fp8_scaled               | 640×640 | 83%      | ≈ 524秒      | ≈ 520秒        |
| fp8_scaled + 4步LoRA加速 | 640×640 | 89%      | ≈ 138秒      | ≈ 79秒         |

由于使用了加速 LoRA 后提速较为明显，在提供的两组工作流中，我们默认启用了使用了加速 LoRA 版本，如果你需要启用另一组的工作流，框选后使用 **Ctrl+B** 即可启用

### 1. 工作流文件下载

请更新你的 ComfyUI 到最新版本，并通过菜单 `工作流` -> `浏览模板` -> `视频` 找到 "**Wan2.2 Fun Inp**" 以加载工作流

或者更新你的 ComfyUI 到最新版本后，下载下面的工作流并拖入 ComfyUI 以加载工作流

<video
  controls
  className="w-full aspect-video"
  src="https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_fun_inp/wan2.2_14B_fun_inp.mp4"
></video>

<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/video_wan2_2_14B_fun_inpaint.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>下载 JSON 格式工作流</p>
</a>

使用下面的素材作为首尾帧

![Wan2.2 Fun Control ComfyUI 工作流起始帧素材](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_fun_inp/start_image.png)
![Wan2.2 Fun Control ComfyUI 工作流起始帧素材](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/video/wan/wan2.2_fun_inp/end_image.png)

### 2. 手动下载模型

**Diffusion Model**
- [wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors)
- [wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors)

**Lightning LoRA (可选，用于加速)**
- [wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors)
- [wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors)

**VAE**
- [wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors)

**Text Encoder**   
- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)

```
ComfyUI/
├───📂 models/
│   ├───📂 diffusion_models/
│   │   ├─── wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors
│   │   └─── wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors
│   ├───📂 loras/
│   │   ├─── wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors
│   │   └─── wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors
│   ├───📂 text_encoders/
│   │   └─── umt5_xxl_fp8_e4m3fn_scaled.safetensors 
│   └───📂 vae/
│       └── wan_2.1_vae.safetensors
```

### 3. 按步骤完成工作流

![步骤图](/images/tutorial/video/wan/wan2_2/wan_2.2_14b_fun_inp.jpg)

<Note>
  这个工作流是使用了 LoRA 的工作流，请确保对应的 Diffusion model 和 LoRA 是一致的
</Note>

1. **High noise** 模型及 **LoRA** 加载
  - 确保 `Load Diffusion Model` 节点加载了 `wan2.2_fun_inpaint_high_noise_14B_fp8_scaled.safetensors` 模型
  - 确保 `LoraLoaderModelOnly` 节点加载了 `wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors`
2. **Low noise** 模型及 **LoRA** 加载
  - 确保 `Load Diffusion Model` 节点加载了 `wan2.2_fun_inpaint_low_noise_14B_fp8_scaled.safetensors` 模型
  - 确保 `LoraLoaderModelOnly` 节点加载了 `wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors`
3. 确保 `Load CLIP` 节点加载了 `umt5_xxl_fp8_e4m3fn_scaled.safetensors` 模型
4. 确保 `Load VAE` 节点加载了 `wan_2.1_vae.safetensors` 模型
5. 首尾帧图片上传，分别上传首尾帧图片素材
6. 在 Prompt 组中输入提示词
7. `WanFunInpaintToVideo` 节点尺寸和视频长度调整
    - 调整 `width` 和 `height` 的尺寸，默认为 `640`, 我们设置了较小的尺寸你可以按需进行修改
    - 调整 `length`, 这里为视频总帧数，当前工作流 fps 为 16, 假设你需要生成一个 5 秒的视频，那么你应该设置 5*16 = 80
8. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频生成
