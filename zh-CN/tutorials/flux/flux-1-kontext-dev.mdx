---
title: "ComfyUI Flux Kontext Dev 原生工作流示例"
description: "ComfyUI Flux Kontext Dev 原生工作流示例。"
sidebarTitle: "Flux.1 Kontext Dev"
---

import PromptTechniques from "/snippets/zh/tutorials/flux/prompt-techniques.mdx";
import UpdateReminder from '/snippets/zh/tutorials/update-reminder.mdx'

<iframe
  className="w-full aspect-video rounded-xl"
  src="//player.bilibili.com/player.html?isOutside=true&aid=114750419636159&bvid=BV14MKfzCELz&cid=30712923473&p=1&autoplay=0"
  title="ComfyUI Selection Toolbox New Features"
  allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
></iframe>

## 关于 FLUX.1 Kontext Dev

FLUX.1 Kontext 是 Black Forest Labs 推出的突破性多模态图像编辑模型，支持文本和图像同时输入，能够智能理解图像上下文并执行精确编辑。其开发版是一个拥有 120 亿参数的开源扩散变压器模型，具有出色的上下文理解能力和角色一致性保持，即使经过多次迭代编辑，也能确保人物特征、构图布局等关键元素保持稳定。

与 FLUX.1 Kontext 套件具备相同的核心能力：
角色一致性：在多个场景和环境中保留图像的独特元素，例如图片中的参考角色或物体。
局部编辑：对图像中的特定元素进行有针对性的修改，而不影响其他部分。
风格参考：根据文本提示，在保留参考图像独特风格的同时生成新颖场景。
交互速度：图像生成和编辑的延迟极小。

虽然之前发布的 API 版本提供了最高的保真度和速度，但 FLUX.1 Kontext [Dev] 完全在本地机器上运行，为希望进行实验的开发者、研究人员和高级用户提供了无与伦比的灵活性。

### 版本说明

- **[FLUX.1 Kontext [pro]** - 商业版本，专注快速迭代编辑
- **FLUX.1 Kontext [max]** - 实验版本，更强的提示遵循能力  
- **FLUX.1 Kontext [dev]** - 开源版本（本教程使用），12B参数，主要用于研究

目前在 ComfyUI 中，你可以使用所有的这些版本，其中 [Pro 及 Max 版本](/zh-CN/tutorials/api-nodes/black-forest-labs/flux-1-kontext) 可以通过 API 节点来进行调用，而 Dev 版本开源版本请参考本篇指南中的说明。


<UpdateReminder/>

## 模型下载

为了使本篇指南的工作流能够顺利运行，你先需要下载下面的模型文件,你也可以直接加载对应工作流下直接获取模型的下载链接，对应的工作流已经包含了模型文件的下载信息。

**Diffusion Model**

- [flux1-dev-kontext_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors)

<Tip>
如果你想要使用原始权重，可以访问 Black Forest Labs 的相关仓库获取原始模型权重进行使用。
</Tip>

**VAE**
- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)

**Text Encoder**
- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)
- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) 或 [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)

模型保存位置

```
📂 ComfyUI/
├── 📂 models/
│   ├── 📂 diffusion_models/
│   │   └── flux1-dev-kontext_fp8_scaled.safetensors
│   ├── 📂 vae/
│   │   └── ae.safetensor
│   └── 📂 text_encoders/
│       ├── clip_l.safetensors
│       └── t5xxl_fp16.safetensors 或者 t5xxl_fp8_e4m3fn_scaled.safetensors
```

## Flux.1 Kontext Dev 工作流

这个工作流使用了 `Load Image(from output)` 节点来加载需要编辑的图像，可以让你更方便地获取到编辑后的图像，从而进行多轮次编辑

### 1. 工作流及输入图片下载

下载下面的文件，并拖入 ComfyUI 中加载对应工作流

![ComfyUI Flux.1 Kontext Pro Image API 节点 工作流](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/flux/kontext/dev/flux_1_kontext_dev_basic.png)

**输入图片**

![ComfyUI Flux Kontext 原生工作流输入](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/flux/kontext/dev/rabbit.jpg)

### 2. 按步骤完成工作流的运行

![工作流步骤图](/images/tutorial/flux/flux_1_kontext_dev_basic_step_guide.jpg)
你可参考图片中的序号来完成图工作流的运行：

1. 在 `Load Diffusion Model` 节点中加载 `flux1-dev-kontext_fp8_scaled.safetensors` 模型
2. 在 `DualCLIP Load` 节点中确保： `clip_l.safetensors` 及 `t5xxl_fp16.safetensors` 或 `t5xxl_fp8_e4m3fn_scaled.safetensors` 已经加载
3. 在 `Load VAE` 节点中确保加载 `ae.safetensors` 模型
4. 在 `Load Image(from output)` 节点中加载提供的输入图像
5. 在 `CLIP Text Encode` 节点中修改提示词，仅支持英文
5. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流

<PromptTechniques/>