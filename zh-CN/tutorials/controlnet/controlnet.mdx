---
title: "ComfyUI ControlNet 使用示例"
description: "本篇将引导了解基础的 ControlNet 概念，并在 ComfyUI 中完成对应的图像生成"
sidebarTitle: "ControlNet"
---

在 AI 图像生成过程中，要精确控制图像生成并不是一键容易的事情，通常需要通过许多次的图像生成才可能生成满意的图像，但随着 ControlNet 的出现，这个问题得到了很好的解决。

ControlNet 是一种基于扩散模型（如 Stable Diffusion）的条件控制生成模型，最早由[张吕敏（Lvmin Zhang）](https://lllyasviel.github.io/)与 Maneesh Agrawala 等人于 2023 年提出[Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543)

ControlNet 模型通过引入多模态输入条件（如边缘检测图、深度图、姿势关键点等），显著提升了图像生成的可控性和细节还原能力。
使得我们可以进一步开始控制图像的风格、细节、人物姿势、画面结构等等，这些限定条件让图像生成变得更加可控，在绘图过程中也可以同时使用多个 ControlNet 模型，以达到更好的效果。

在没有 ControlNet 之前，我们每次只能让模型生成图像，直到生成我们满意的图像，充满了随机性。

![ComfyUI 随机种子生成的图片](/images/tutorial/controlnet/generated_with_random_seed.jpg)

但随着 ControlNet 的出现，我们可以通过引入额外的条件，来控制图像的生成，比如我们可以使用一张简单的涂鸦，来控制图像的生成，就可以生成差不多类似的图片。

![ComfyUI 涂鸦控制图像生成](/images/tutorial/controlnet/scribble_example.jpg)

在本示例中，我们将引导你完成在 [ComfyUI](https://github.com/comfyanonymous/ComfyUI) 中 ControlNet 模型得安装与使用, 并完成一个涂鸦控制图像生成的示例。

![ComfyUI ControlNet 工作流](/images/tutorial/controlnet/controlnet.png)

## ControlNet 图片预处理相关说明

不同类型的 ControlNet 模型，通常需要使用不同类型的参考图：

![参考图](https://github.com/Fannovel16/comfyui_controlnet_aux/blob/main/examples/CNAuxBanner.jpg?raw=true)

由于目前 **Comfy Core** 节点中，不包含所有类型的预处理器类型，但在本文档的实际示例中，我们都将提供已经经过处理后的图片，
但在实际使用过程中，你可能需要借助一些自定义节点来对图片进行预处理，以满足不同 ControlNet 模型的需求，下面是一些相关的插件

- [ComfyUI-Advanced-ControlNet](https://github.com/Kosinkadink/ComfyUI-Advanced-ControlNet)
- [ComfyUI ControlNet aux](https://github.com/Fannovel16/comfyui_controlnet_aux)

## ComfyUI ControlNet 工作流示例讲解

### 1. 模型安装

请下载以下模型并放置到指定目录中：
- [dreamCreationVirtual3DECommerce_v10.safetensors](https://civitai.com/api/download/models/731340?type=Model&format=SafeTensor&size=full&fp=fp16)
- [vaeFtMse840000EmaPruned_vaeFtMse840k.safetensors](https://civitai.com/api/download/models/311162?type=Model&format=SafeTensor)
- [control_v11p_sd15_scribble_fp16.safetensors](https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors?download=true)

```
ComfyUI/
├── models/
│   ├── checkpoints/
│   │   └── dreamCreationVirtual3DECommerce_v10.safetensors
│   ├── vae/
│   │   └── vaeFtMse840000EmaPruned_vaeFtMse840k.safetensors
│   └── controlnet/
│       └── control_v11p_sd15_scribble_fp16.safetensors
```

<Note>
VAE 模型在实际使用过程中，可能需要使用不同的 VAE 模型，请根据实际情况选择合适的 VAE 模型
</Note>

### 2. ControlNet 工作流素材

请下载下面的工作流图片,并拖入 ComfyUI 以加载工作流

![ComfyUI 工作流 - ControlNet](/images/tutorial/controlnet/scribble_controlnet.png)

<Tip>
Metadata 中包含工作流 json 的图片可直接拖入 ComfyUI 或使用菜单 `Workflows` -> `Open（ctrl+o）` 来加载对应的工作流。
</Tip>

请下载下面的图片，我们将会将它作为 ControlNet 的输入图片

![ComfyUI 涂鸦图片](/images/tutorial/controlnet/scribble_input.png)

### 3. 按步骤完成工作流的运行

![ComfyUI 工作流 - ControlNet 流程图](/images/tutorial/controlnet/flow_diagram_scribble.png)

1. 确保`Load Checkpoint`可以加载 **dreamCreationVirtual3DECommerce_v10.safetensors**
2. 确保`Load VAE`可以加载 **vaeFtMse840000EmaPruned_vaeFtMse840k.safetensors**
3. 在`Load Image`中点击`Upload` 选择之前提供的输入图片
4. 确保`Load ControlNet`可以加载 **control_v11p_sd15_scribble_fp16.safetensors**
5. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行图片的生成

## 相关节点讲解
### Load ControlNet 节点讲解

![load controlnet](/images/comfy_core/conditioning/controlnet/load_controlnet.jpg)

位于`ComfyUI\models\controlnet` 的模型会被 ComfyUI 检测到，并在这个节点中识别并加载

### Apply ControlNet 节点讲解

![apply controlnet ](/images/comfy_core/conditioning/controlnet/apply_controlnet.jpg)

这个节点接受 `load controlnet` 加载的 ControlNet 模型，并根据输入的图片，生成对应的控制条件。

## Apply ControlNet 输入类型
| 参数名称         | 作用                                                                                        |
| --------------- | ------------------------------------------------------------------------------------------ |
| `positive`      | 正向条件                                                                                    |
| `negative`      | 负向条件                                                                                    |
| `control_net`   | 要应用的controlNet模型                                                                       |
| `image`         | 用于 controlNet 应用参考的预处理器处理图片                                                       |
| `vae`           | Vae模型输入                                                                                  |
| `strength`      | 应用 ControlNet 的强度，越大则 ControlNet 对生成图像的影响越大                                    |
| `start_percent` | 确定开始应用controlNet的百分比，比如取值0.2，意味着ControlNet的引导将在扩散过程完成20%时开始影响图像生成 |
| `end_percent`   | 确定结束应用controlNet的百分比，比如取值0.8，意味着ControlNet的引导将在扩散过程完成80%时停止影响图像生成 |

## Apply ControlNet 输出类型
| 参数名称    | 作用                                |
| -----------| ---------------------------------- |
| `positive` | 应用了 ControlNet 处理后的正向条件数据 |
| `negative` | 应用了 ControlNet 处理后的负向条件数据 |

你可以使用链式链接来应用多个 ControlNet 模型，如下图所示
![apply controlnet chain link](/images/tutorial/controlnet/apply_controlnet_chain_link.jpg)

## 开始你的尝试

1. 试着制作类似的涂鸦图片，并使用 ControlNet 模型生成图像
2. 调整 Apply ControlNet 节点的 `Control Strength` 参数，来控制 ControlNet 模型对生成图像的影响
