---
title: "ComfyUI ControlNet 混合使用示例"
description: "我们将在本篇示例中，完成多个 ControlNet 混合使用，学会使用多个 ControlNet 模型来控制图像生成"
sidebarTitle: "ControlNet 混合使用"
---

## ControlNet 混合使用的原理和优势

在 AI 图像生成中，单一的控制条件往往难以满足复杂场景的需求。混合使用多个 ControlNet 可以同时控制图像的不同区域或不同方面，实现更精确的图像生成控制。

### 混合 ControlNet 的核心原理

当我们混合使用多个 ControlNet 时，每个 ControlNet 会根据其专长区域对图像生成过程施加影响。ComfyUI 通过 `Apply ControlNet` 节点的链式连接方式，允许多个 ControlNet 条件按顺序叠加应用：

![apply controlnet chain link](/images/tutorial/controlnet/apply_controlnet_chain_link.jpg)

### 混合 ControlNet 的应用场景

混合 ControlNet 有两种主要应用场景：

1. **区域分治控制**：使用不同 ControlNet 控制图像的不同区域（如本教程示例）
   - 例如：使用 Pose ControlNet 控制左侧人物，Scribble ControlNet 控制右侧场景

2. **多维度控制**：使用不同 ControlNet 控制同一主体的不同方面
   - 例如：使用 Pose ControlNet 控制人物姿势，同时使用 Depth ControlNet 控制空间感

### 为什么要混合多个 ControlNet？

1. **场景复杂性**：复杂场景需要多种控制条件共同作用
2. **精细控制**：通过调整每个 ControlNet 的强度参数，可以精确控制各部分的影响程度
3. **互补效果**：不同类型的 ControlNet 可以互相补充，弥补单一控制的局限性
4. **创意表达**：组合不同控制可以产生独特的创意效果

## ComfyUI ControlNet 区域分治混合示例

在本示例中，我们将使用 **Pose ControlNet** 和 **Scribble ControlNet** 的组合来生成一张包含多个元素的场景：左侧由 Pose ControlNet 控制的人物和右侧由 Scribble ControlNet 控制的猫咪滑板车。

### 1. ControlNet 混合使用工作流素材

请下载下面的工作流图片,并拖入 ComfyUI 以加载工作流
![ComfyUI 工作流 - Mixing ControlNet](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/controlnet/mixing_controlnets.png)

<Tip>
该工作流图片包含 Metadata 数据，可直接拖入 ComfyUI 或使用菜单 `Workflows` -> `Open（ctrl+o）` 加载。系统会自动检测并提示下载所需模型。
</Tip>

用于输入的 pose 图片（控制左侧人物姿态）:

![ComfyUI 工作流 - Mixing ControlNet 输入图片](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/controlnet/mixing_controlnets_input.png)

用于输入的 scribble 图片（控制右侧猫咪和滑板车）:

![ComfyUI 工作流 - Mixing ControlNet 输入图片](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/controlnet/mixing_controlnets_input_scribble.png)

### 2. 手动模型安装

<Note>
如果你网络无法顺利完成对应模型的自动下载，请尝试手动下载下面的模型，并放置到指定目录中
</Note>

- [awpainting_v14.safetensors](https://civitai.com/api/download/models/624939?type=Model&format=SafeTensor&size=full&fp=fp16)
- [control_v11p_sd15_scribble_fp16.safetensors](https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors?download=true)
- [control_v11p_sd15_openpose_fp16.safetensors](https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors?download=true)
- [vae-ft-mse-840000-ema-pruned.safetensors](https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors?download=true)

```
ComfyUI/
├── models/
│   ├── checkpoints/
│   │   └── awpainting_v14.safetensors
│   ├── controlnet/
│   │   └── control_v11p_sd15_scribble_fp16.safetensors
│   │   └── control_v11p_sd15_openpose_fp16.safetensors
│   ├── vae/
│   │   └── vae-ft-mse-840000-ema-pruned.safetensors
```

### 3. 按步骤完成工作流的运行

![ComfyUI 工作流 - Mixing ControlNet 流程图](/images/tutorial/controlnet/flow_diagram_mixing_controlnet.jpg)

按照图片中的数字标记，执行以下步骤：

1. 确保`Load Checkpoint`可以加载 **awpainting_v14.safetensors**
2. 确保`Load VAE`可以加载 **vae-ft-mse-840000-ema-pruned.safetensors**

第一组 ControlNet 使用 Openpose 模型:
3. 确保`Load ControlNet Model`加载 **control_v11p_sd15_openpose_fp16.safetensors**
4. 在`Load Image`中点击`Upload` 上传之前提供的 pose 图片

第二组 ControlNet 使用 Scribble 模型:
5. 确保`Load ControlNet Model`加载 **control_v11p_sd15_scribble_fp16.safetensors**
6. 在`Load Image`中点击`Upload` 上传之前提供的 scribble 图片
7. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行图片的生成

## 区域分治混合 ControlNet 工作流详解

### 工作流结构分析

在这个示例工作流中，我们使用的是区域分治的混合方式：

1. **基础模型加载**：首先加载基础模型和 VAE
2. **人物控制**：使用 Pose ControlNet 控制图像左侧的人物姿态
3. **场景控制**：使用 Scribble ControlNet 控制图像右侧的猫咪和滑板车
4. **采样生成**：KSampler 节点结合两种控制条件生成最终图像

这种区域分治的方法允许我们在一张图像中创建复杂的场景组合，每个区域都由最适合的 ControlNet 类型进行控制。

### 关键参数设置与优化

#### 强度平衡

当控制图像不同区域时，强度参数的平衡尤为重要：
- 如果一个区域的 ControlNet 强度明显高于另一个，可能导致该区域的控制效果过强而抑制另一区域
- 推荐为不同区域的 ControlNet 设置相似的强度值，例如都设为 1.0

#### 提示词技巧

在区域分治混合中，提示词需要同时包含两个区域的描述：

```
"A woman in red dress, a cat riding a scooter, detailed background, high quality"
```

这样的提示词同时涵盖了人物和猫咪滑板车，确保模型能够同时关注两个控制区域。

## 同一主体多维控制的混合应用

除了本例展示的区域分治混合外，另一种常见的混合方式是对同一主体进行多维控制。例如：

### 人物多维控制组合

- **Pose + Depth**：控制人物姿势及空间感
- **Pose + Canny**：控制人物姿势及边缘细节
- **Pose + Reference**：控制人物姿势但参考特定风格

在这种应用中，多个 ControlNet 的参考图应该对准同一主体，并调整各自的强度确保适当平衡。

## ControlNet 混合使用的高级技巧

### 1. 顺序调整技巧

ControlNet 的应用顺序会影响最终效果：
- 在区域分治应用中，通常将主要主体的 ControlNet 放在前面
- 在同一主体多维控制中，通常将最重要的方面放在链条的最后

### 2. 三种以上 ControlNet 混合

对于复杂场景，可以混合三种或更多 ControlNet：
- **区域分治**：每个 ControlNet 控制场景的不同区域
- **混合控制**：部分 ControlNet 控制同一区域的不同方面

### 3. 常见问题排查

在混合使用中遇到的常见问题：

**问题1: 区域竞争**
- 症状：一个区域的控制效果覆盖或影响了另一个区域
- 解决方案：确保参考图中区域明确分开，调整两个 ControlNet 的强度平衡

**问题2: 风格不一致**
- 症状：不同区域的艺术风格明显不同
- 解决方案：在提示词中加强整体风格描述，或添加额外的参考风格 ControlNet

**问题3: 画面混乱**
- 症状：不同区域的元素相互干扰，画面杂乱
- 解决方案：在提示词中明确指出元素位置（左侧、右侧），或适当降低复杂度

通过灵活组合不同类型的 ControlNet 并指定其控制区域，你可以创造出复杂而和谐的场景，同时保持对各个元素的精确控制。尝试不同的组合和设置，探索混合 ControlNet 带来的创作可能性！


