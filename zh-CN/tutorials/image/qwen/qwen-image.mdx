---
title: "Qwen-Image ComfyUI原生工作流示例"
description: "Qwen-Image 是一个拥有 20B 参数的 MMDiT（多模态扩散变换器）模型，基于 Apache 2.0 许可证开源。"
sidebarTitle: "Qwen-Image"
---

import UpdateReminder from '/snippets/zh/tutorials/update-reminder.mdx'


**Qwen-Image** 是阿里巴巴通义千问团队发布的首个图像生成基础模型，这是一个拥有 20B 参数的 MMDiT（多模态扩散变换器）模型，基于 Apache 2.0 许可证开源。该模型在**复杂文本渲染**和**精确图像编辑**方面取得了显著进展，无论是英语还是中文等多种语言都能实现高保真输出。

**模型亮点**：
- **卓越的多语言文本渲染**：支持英语、中文、韩语、日语等多种语言的高精度文本生成，保持字体细节和布局一致性
- **多样化艺术风格**：从照片级真实到印象派绘画，从动漫美学到极简设计，流畅适应各种创意提示

*相关链接**:
 - [GitHub](https://github.com/QwenLM/Qwen-Image)
 - [Hugging Face](https://huggingface.co/Qwen/Qwen-Image)
 - [ModelScope](https://modelscope.cn/models/qwen/Qwen-Image)

 另外目前 Qwen-Image 有多种 ControlNet 支持
- [Qwen-Image-DiffSynth-ControlNets/model_patches](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/tree/main/split_files/model_patches): 包括 canny、depth、inpaint 三个模型
- [qwen_image_union_diffsynth_lora.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/blob/main/split_files/loras/qwen_image_union_diffsynth_lora.safetensors): 图像结构控制lora 支持 canny、depth、pose、lineart、softedge、normal、openpose
- instanX ControlNet: 待更新

## Qwen-Image 原生工作流示例

<UpdateReminder />

在本篇文档所附工作流中使用的不同模型有三种
1. Qwen-Image 原版模型 fp8_e4m3fn
2. 8步加速版： Qwen-Image 原版模型 fp8_e4m3fn 使用 lightx2v 8步 LoRA,
3. 蒸馏版:Qwen-Image 蒸馏版模型 fp8_e4m3fn

**显存使用参考**
GPU: RTX4090D 24GB

| 使用模型                           | VRAM Usage | 首次生成   | 第二次生成  |
| --------------------------------- | ---------- | -------- | ---------- |
| fp8_e4m3fn                        | 86%        | ≈ 94s    | ≈ 71s      |
| fp8_e4m3fn 使用 lightx2v 8步 LoRA  | 86%        | ≈ 55s    | ≈ 34s      |
| 蒸馏版 fp8_e4m3fn                  | 86%        | ≈ 69s    | ≈ 36s      |

### 1. 工作流文件

更新 ComfyUI 后你可以从模板中找到工作流文件，或者将下面的工作流拖入 ComfyUI 中加载
![Qwen-image 文生图工作流](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/image/qwen/qwen-image.png)

<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_qwen_image.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>下载原始版 JSON 格式工作流</p>
</a>

蒸馏版
<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/image/qwen/image_qwen_image_distill.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>下载蒸馏版JSON 格式工作流</p>
</a>
### 2. 模型下载

**你可以在 ComfyOrg 仓库找到的版本**
- Qwen-Image_bf16 (40.9 GB)
- Qwen-Image_fp8 (20.4 GB)
- 蒸馏版本 (非官方，仅需 15 步)


所有模型均可在 [Huggingface](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) 或者 [魔搭](https://modelscope.cn/models/Comfy-Org/Qwen-Image_ComfyUI/files) 找到

**Diffusion model**

- [qwen_image_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_fp8_e4m3fn.safetensors)

Qwen_image_distill

- [qwen_image_distill_full_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_fp8_e4m3fn.safetensors)
- [qwen_image_distill_full_bf16.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/non_official/diffusion_models/qwen_image_distill_full_bf16.safetensors)

<Note>
 - 蒸馏版本原始作者建议在 15 步 cfg 1.0
- 经测试该蒸馏版本在 10 步 cfg 1.0 下表现良好，根据你想要的图像类型选择 euler 或 res_multistep   
</Note>

**LoRA**

- [Qwen-Image-Lightning-8steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors)

**Text encoder**

- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)

**VAE**

- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)

模型保存位置

```
📂 ComfyUI/
├── 📂 models/
│   ├── 📂 diffusion_models/
│   │   ├── qwen_image_fp8_e4m3fn.safetensors
│   │   └── qwen_image_distill_full_fp8_e4m3fn.safetensors ## 蒸馏版
│   ├── 📂 loras/
│   │   └── Qwen-Image-Lightning-8steps-V1.0.safetensors   ## 8步加速 LoRA 模型
│   ├── 📂 vae/
│   │   └── qwen_image_vae.safetensors
│   └── 📂 text_encoders/
│       └── qwen_2.5_vl_7b_fp8_scaled.safetensors
```

### 3. 工作流使用说明

![步骤图](/images/tutorial/image/qwen/image_qwen_image-guide.jpg)

1. 确保 `Load Diffusion Model`节点加载了`qwen_image_fp8_e4m3fn.safetensors`
2. 确保 `Load CLIP`节点中加载了`qwen_2.5_vl_7b_fp8_scaled.safetensors`
3. 确保 `Load VAE`节点中加载了`qwen_image_vae.safetensors`
4. 确保 `EmptySD3LatentImage`节点中设置好了图片的尺寸
5. 在`CLIP Text Encoder`节点中设置好提示词，目前经过测试目前至少支持：英语、中文、韩语、日语、意大利语等
6. 如果需要启用 lightx2v 的 8 步加速 LoRA ，请选中后用 `Ctrl + B` 启用该节点，并按 序号`8` 处的设置参数修改 Ksampler 的设置设置
7. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流
8. 对于不同版本的模型和工作流的对应 KSampler 的参数设置

<Note>
 蒸馏版模型和 lightx2v 的 8 步加速 LoRA 似乎并不兼容，你可以测试具体的组合参数来验证组合使用的方式是否可行
</Note>


## Qwen Image ControlNet DiffSynth-ControlNets Model Patches 工作流

这个模型实际上并不是一个 controlnet，而是一个 Model patch， 支持 canny、depth、inpaint 三种不同的控制模式

原始模型地址：[DiffSynth-Studio/Qwen-Image ControlNet](https://www.modelscope.cn/collections/Qwen-Image-ControlNet-6157b44e89d444) 
Comfy Org rehost 地址： [Qwen-Image-DiffSynth-ControlNets/model_patches](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/tree/main/split_files/model_patches)


### 1. 工作流及输入图片

下载下面的图片拖入 ComfyUI 中以加载对应的工作流
![workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-controlnet-model-patch/image_qwen_image_controlnet_patch.png)

<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_qwen_image_controlnet_patch.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>下载 JSON 格式工作流</p>
</a>

下载下面的图片作为输入图片：

![input](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-controlnet-model-patch/input.png)

### 2. 模型链接

其它模型与 Qwen-Image 基础工作流一致，你只需下载下面的模型并保存到 `ComfyUI/models/model_patches` 文件夹中

- [qwen_image_canny_diffsynth_controlnet.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/resolve/main/split_files/model_patches/qwen_image_canny_diffsynth_controlnet.safetensors)
- [qwen_image_depth_diffsynth_controlnet.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/resolve/main/split_files/model_patches/qwen_image_depth_diffsynth_controlnet.safetensors)
- [qwen_image_inpaint_diffsynth_controlnet.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/resolve/main/split_files/model_patches/qwen_image_inpaint_diffsynth_controlnet.safetensors)


### 3. 工作流使用说明

目前 diffsynth 有三个 patch 的模型： Canny、Detph、Inpaint 三个模型

如果你是第一次使用 ControlNet 相关的工作流，你需要了解的是，用于控制的图片需要预处理成受支持的图像才可以被模型使用和识别

![输入类型示意](/images/tutorial/image/qwen/controlnet_input_types.jpg)

- Canny: 处理后的 canny ， 线稿轮廓
- Detph: 预处理后的深度图，体现空间关系
- Inpaint: 需要用 Mask 标记需要重绘的部分

由于这个 patch 模型分为了三个不同的模型，所以你需要在输入时选择正确的预处理类型来保证图像的正确预处理

**Canny 模型 ControlNet 使用说明**

![Canny 工作流](/images/tutorial/image/qwen/image_qwen_image_controlnet_patch-canny.jpg)
1. 确保对应 `qwen_image_canny_diffsynth_controlnet.safetensors` 已被加载
2. 上传输入图片，用于后续处理
3. Canny 节点是原生的预处理节点，它将按照你设置的参数，将输入图像进行预处理，控制生成
4. 如果需要可以修改 `QwenImageDiffsynthControlnet` 节点的 `strength` 强度来控制线稿控制的强度
5. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流

> 对于 qwen_image_depth_diffsynth_controlnet.safetensors 使用，需要将图像预处理成 detph 深度图，替换掉 `image proccessing` 图，对于这部分的使用，请参考本篇文档中 InstantX 的处理方法，其它部分与 Canny 模型的使用类似

**Inpaint 模型 ControlNet 使用说明**
![Inpaint 工作流](/images/tutorial/image/qwen/image_qwen_image_controlnet_patch-inpaint.jpg)

对于 Inpaint 模型，它需要使用 [蒙版编辑器](/zh-CN/interface/maskeditor)，来绘制一个蒙版然后作为输入控制条件

1. 确保 `ModelPatchLoader` 加载的是 `qwen_image_inpaint_diffsynth_controlnet.safetensors` 模型
2. 上传图片，并使用[蒙版编辑器](/zh-CN/interface/maskeditor) 绘制蒙版，你需要将对应 `Load Image`节点的 `mask` 输出连接到 `QwenImageDiffsynthControlnet` 的 `mask` 输入才能保证对应的蒙版被加载
3. 使用 `Ctrl-B` 快捷键，将原本工作流中的 Canny 设置为绕过模式，来使得对应的 Canny 节点处理不生效
4. 在 `CLIP Text Encoder`  输入你需要将蒙版部分修改成样式 
5. 如需要可以修改 `QwenImageDiffsynthControlnet` 节点的 `strength` 强度来控制对应的控制强度
6. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流

## Qwen Image union ControlNet LoRA 工作流

原始模型地址：[DiffSynth-Studio/Qwen-Image-In-Context-Control-Union](https://www.modelscope.cn/models/DiffSynth-Studio/Qwen-Image-In-Context-Control-Union/)
Comfy Org reshot 地址: [qwen_image_union_diffsynth_lora.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/blob/main/split_files/loras/qwen_image_union_diffsynth_lora.safetensors): 图像结构控制lora 支持 canny、depth、post、lineart、softedge、normal、openpose

### 1. 工作流及输入图片

下载下面的图片并拖入 ComfyUI 以加载工作流
![workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-union-control-lora/image_qwen_image_union_control_lora.png)
<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_qwen_image_union_control_lora.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>下载 JSON 格式工作流</p>
</a>

下载下面的图片作为输入图片

![workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-union-control-lora/input.png)

### 2. 模型链接

下载下面的模型，由于这是一个 LoRA 模型，所以需要保存到 `ComfyUI/models/loras/` 文件夹下
-  [qwen_image_union_diffsynth_lora.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-DiffSynth-ControlNets/blob/main/split_files/loras/qwen_image_union_diffsynth_lora.safetensors): 图像结构控制lora 支持 canny、depth、post、lineart、softedge、normal、openpose

### 3. 工作流说明

这个模型是一个统一的控制 LoRA, 支持  canny、depth、pose、lineart、softedge、normal、openpose 等控制, 由于许多的图像预处理原生节点并未完全支持，所以你应该需要类似 [comfyui_controlnet_aux](https://github.com/Fannovel16/comfyui_controlnet_aux) 来完成其它图像的预处理

![Union Control LoRA](/images/tutorial/image/qwen/image_qwen_image_union_control_lora.jpg)

1. 确保 `LoraLoaderModelOnly` 正确加载了 `qwen_image_union_diffsynth_lora.safetensors`  模型
2. 上传输入图像
3. 如需要你可以调整 `Canny` 节点的参数，由于不同的输入图像需要不同的参数设置来获得更好的图像预处理结果，你可以尝试调整对应的参数值来获得更多/更少细节
4. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流

> 其它类型的类型的控制，也是需要将图像处理的部分替换

## Qwen Image InstantX ControlNet 工作流

[待更新]
{/* 这是一个 ControlNet 模型

### 1. 工作流及输入图片

下载下面的图片并拖入 ComfyUI 以加载工作流
![workflow](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-instantx-controlnet/image_qwen_image_instantx_controlnet.png)

<a className="prose"  target='_blank'  href="https://raw.githubusercontent.com/Comfy-Org/workflow_templates/refs/heads/main/templates/image_qwen_image_instantx_controlnet.json" style={{ display: 'inline-block', backgroundColor: '#0078D6', color: '#ffffff', padding: '10px 20px', borderRadius: '8px', borderColor: "transparent", textDecoration: 'none', fontWeight: 'bold'}}>
    <p className="prose" style={{ margin: 0, fontSize: "0.8rem" }}>下载 JSON 格式工作流</p>
</a>

下载下面的图片作为输入
![input](https://raw.githubusercontent.com/Comfy-Org/example_workflows/refs/heads/main/image/qwen/qwen-image-instantx-controlnet/input.jpg)
### 2. 模型链接

待更新


**Lotus Depth 模型**

我们将使用这个模型来生成图像的深度图，它需要安装以下两个模型：

**Diffusion Model**

- [lotus-depth-d-v1-1.safetensors](https://huggingface.co/Comfy-Org/lotus/resolve/main/lotus-depth-d-v1-1.safetensors) 

**VAE Model**

- [vae-ft-mse-840000-ema-pruned.safetensors](https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors)  或者任意的 SD1.5 的 VAE 都可以使用

```
ComfyUI/
├── models/
│   ├── diffusion_models/
│   │   └─── lotus-depth-d-v1-1.safetensors
│   └── vae/
│       └──  lvae-ft-mse-840000-ema-pruned.safetensors
```



### 3. 工作流说明

![流程说明](/images/tutorial/image/qwen/image_qwen_image_instantx_controlnet.jpg)

1. 确保 `Load ControlNet Model` 节点正确加载了 `qQwen-Image-INstanX-ControlNet-Unoin.safetensors`  模型
2. 上传输入图像
3. 这里是一个子图，这里是 ComfyUI 支持的 lotus Depth 模型，你可以在模板中找到 Lotus Depth 或者编辑对应子图了解对应工作流
4. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来运行工作流 */}