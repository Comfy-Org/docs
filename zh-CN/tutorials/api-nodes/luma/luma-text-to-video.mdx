---
title: "Luma Text to Video API 节点 ComfyUI 官方示例"
description: "本文将介绍如何在 ComfyUI 中使用 Luma Text to Video API 节点的相关功能"
sidebarTitle: "Luma Text to Video"
---

import ReqHint from "/snippets/zh/tutorials/api-nodes/req-hint.mdx";
import UpdateReminder from "/snippets/zh/tutorials/update-reminder.mdx";

[Luma Text to Video](/zh-CN/built-in-nodes/api-node/video/luma/luma-text-to-video) 节点允许你使用Luma AI的创新视频生成技术，通过文本描述创建高质量、流畅的视频内容。

本篇指南中，我们将引导你如何使用对应节点来进行文本到视频的工作流设置。

<ReqHint/>
<UpdateReminder/>

## Luma Text to Video 节点文档

你可查阅下面的文档了解对应节点的详细参数设置等

<Card title="Luma Text to Video 节点文档" icon="book" href="/zh-CN/built-in-nodes/api-node/video/luma/luma-text-to-video">
Luma Text to Video API 节点说明文档
</Card>

<Card title="Luma Concepts 节点文档" icon="book" href="/zh-CN/built-in-nodes/api-node/video/luma/luma-concepts">
Luma Concepts API 节点说明文档
</Card>

## Luma Text to Video API 节点文本到视频工作流

Luma Text to Video 节点需要提供文本提示词来描述生成视频内容。在本篇指南中，我们制作了使用`prompt`和`luma_concepts`的示例，让你体验Luma AI在视频生成上的优秀能力。

### 1. 工作流文件下载

下面的视频的`metadata`中已经包含工作流信息，请下载并拖入 ComfyUI 中加载对应工作流。

![Luma 文本到视频工作流](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/luma/t2v/luma_t2v.mp4)

### 2. 按步骤完成工作流的运行

![Luma 文本到视频工作流步骤图](/images/tutorial/api_nodes/luma/luma_t2v_step_guide.jpg)

你可参考图片中的序号来完成最基础的工作流运行：  
1. 在 `Luma Text to Video` 节点中编写提示词，描述你希望生成的视频内容
3. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频的生成
4. 等待 API 返回结果后，你可在 `Save Video` 节点中查看生成的视频，对应的视频也会被保存至 `ComfyUI/output/` 目录下

> (可选)修改 `Luma Concepts` 节点来控制相机运动效果，为视频添加专业的镜头语言

### 3. 补充说明

- **提示词撰写**：尽可能详细地描述场景、主体、动作和氛围，以获得最佳生成效果
- **Luma Concepts**：主要用于控制相机运动，提供更专业的视频镜头效果
- **Seed 参数**：仅用于确定节点是否应重新运行，但实际生成结果与种子值无关
- **模型选择**：不同的视频生成模型有不同的特点，可以通过调整 model 参数来选择
- **分辨率与时长**：可以通过 resolution 和 duration 参数来调整输出视频的分辨率和时长
- **Ray 1.6 模型注意事项**：当使用 Ray 1.6 模型时，duration 和 resolution 参数将不会生效