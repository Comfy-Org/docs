---
title: "Luma Image to Video API 节点 ComfyUI 官方示例"
description: "本文将介绍如何在 ComfyUI 中使用 Luma Image to Video API 节点的相关功能"
sidebarTitle: "Luma Image to Video"
---

import ReqHint from "/snippets/zh/tutorials/api-nodes/req-hint.mdx";

[Luma Image to Video](/zh-CN/built-in-nodes/api-node/video/luma/luma-image-to-video) 节点允许你使用Luma AI的先进技术将静态图像转换为流畅、动态的视频内容，为图像赋予生命力和动态特性。

本篇指南中，我们将引导你如何使用对应节点来进行图像到视频的工作流设置。

<ReqHint/>

## Luma Image to Video 节点文档

你可查阅下面的文档了解对应节点的详细参数设置等

<Card title="Luma Image to Video 节点文档" icon="book" href="/zh-CN/built-in-nodes/api-node/video/luma/luma-image-to-video">
Luma Image to Video API 节点说明文档
</Card>

<Card title="Luma Concepts 节点文档" icon="book" href="/zh-CN/built-in-nodes/api-node/video/luma/luma-concepts">
Luma Concepts API 节点说明文档
</Card>

## Luma Image to Video API 节点图像到视频工作流

Luma Image to Video 节点需要至少提供一个图像输入（`first_image`或`last_image`），结合文本提示词来确定视频的动态效果。在本篇指南中，我们制作了使用`first_image`和`luma_concepts`的示例，让你体验Luma AI在视频生成上的优秀能力。

### 1. 工作流文件下载

下面的视频的`metadata`中已经包含工作流信息，请下载并拖入 ComfyUI 中加载对应工作流。

![Luma 图像到视频工作流](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/luma/i2v/luma_i2v.mp4)

请下载下面的图片，我们将会用作输入：

![输入图片](https://raw.githubusercontent.com/Comfy-Org/example_workflows/main/api_nodes/luma/i2v/input.png)

### 2. 按步骤完成工作流的运行

![Luma 图像到视频工作流步骤图](/images/tutorial/api_nodes/luma/luma_i2v_step_guide.jpg)

你可参考图片中的序号来完成最基础的工作流运行：  
1. 在 `first_image` 节点中上传你的输入图像
2. (可选)在 Luma Image to Video 节点中编写提示词，描述你希望视频如何动态展示图像
3. (可选)修改 `Luma Concepts` 节点来控制相机运动效果，为视频添加专业的镜头语言
4. 点击 `Run` 按钮，或者使用快捷键 `Ctrl(cmd) + Enter(回车)` 来执行视频的生成
5. 等待 API 返回结果后，你可在 `Save Video` 节点中查看生成的视频，对应的视频也会被保存至 `ComfyUI/output/` 目录下

### 3. 补充说明

- **输入图像要求**：`first_image` 和 `last_image` 至少需要提供一个，每个输入最多只接受1张图片
- **Luma Concepts**：主要用于控制相机运动，提供更专业的视频镜头效果
- **Seed 参数**：仅用于确定节点是否应重新运行，但实际生成结果与种子值无关
- **启用输入节点**：要启用对应的输入请在目前紫色"绕过（Bypass）"模式的节点上右键，设置对应的"模式（mode）"为"总是（always）"
- **模型选择**：不同的视频生成模型有不同的特点，可以通过调整 model 参数来选择
- **分辨率与时长**：可以通过 resolution 和 duration 参数来调整输出视频的分辨率和时长