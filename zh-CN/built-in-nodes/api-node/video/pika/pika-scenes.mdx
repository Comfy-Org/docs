---
title: "Pika 2.2 Scenes - ComfyUI 原生节点文档"
description: "使用Pika的AI技术基于多张图像创建连贯场景视频的节点"
sidebarTitle: "Pika 2.2 Scenes"
icon: "circle"
---

![ComfyUI 原生 Pika 2.2 Scenes 节点](/images/built-in-nodes/api_nodes/pika/pika-2-2-scenes.jpg)

Pika 2.2 Scenes 节点允许你使用Pika最新的2.2版本API，基于多张输入图像创建连贯的场景过渡视频。

## 节点功能

此节点连接到Pika的场景生成API，让用户能够提供多达5张图像，并生成这些图像之间自然过渡的视频。这种功能特别适合创建故事板可视化、概念演示或多场景叙事视频。

## 参数说明

### 基本参数

| 参数               | 类型     | 默认值                    | 说明                           |
|-------------------|----------|--------------------------|-------------------------------|
| prompt_text       | 字符串    | ""                       | 描述视频内容和场景的文本提示词     |
| negative_prompt   | 字符串    | ""                       | 指定不希望在视频中出现的元素       |
| seed              | 整数      | 0                        | 生成过程的随机种子               |
| ingredients_mode  | 选择项    | "IngredientsMode.key_frames" | 图像组合模式                |
| resolution        | 选择项    | "Resolution.1152_2048"   | 生成视频的分辨率                |
| duration          | 选择项    | "Duration.four_seconds"  | 生成视频的持续时间               |
| aspect_ratio      | 选择项    | "9:16"                   | 输出视频的宽高比                 |
| image_ingredient_1 | 图像     | -                        | 场景中的第一张图像（必须）         |
| image_ingredient_2 | 图像     | -                        | 场景中的第二张图像（可选）         |
| image_ingredient_3 | 图像     | -                        | 场景中的第三张图像（可选）         |
| image_ingredient_4 | 图像     | -                        | 场景中的第四张图像（可选）         |
| image_ingredient_5 | 图像     | -                        | 场景中的第五张图像（可选）         |

### 输出

| 输出   | 类型   | 说明          |
|--------|--------|--------------|
| VIDEO  | 视频   | 生成的视频结果 |

## 工作原理

Pika 2.2 Scenes 节点分析所有输入图像，理解它们之间的视觉关系，然后创建一个连贯的场景过渡视频。节点将图像和参数发送到Pika的API服务器，处理完成后返回生成的视频结果。

根据所选的组合模式，节点会以不同方式处理图像之间的过渡。"key_frames"模式将图像视为视频中的关键帧，创建平滑的过渡；而其他模式可能会以不同的叙事方式组织场景。

用户可以通过提示词引导场景的风格和内容，而负面提示词则帮助避免不需要的元素。不同的分辨率和持续时间选项适合不同类型的场景效果。

## 源码参考

```python

class PikaScenesV2_2(PikaNodeBase):
    """Pika 2.2 Scenes Node."""

    @classmethod
    def INPUT_TYPES(cls):
        image_ingredient_input = (
            IO.IMAGE,
            {"tooltip": "Image that will be used as ingredient to create a video."},
        )
        return {
            "required": {
                **cls.get_base_inputs_types(
                    PikaBodyGenerate22C2vGenerate22PikascenesPost,
                ),
                "ingredients_mode": model_field_to_node_input(
                    IO.COMBO,
                    PikaBodyGenerate22C2vGenerate22PikascenesPost,
                    "ingredientsMode",
                    enum_type=IngredientsMode,
                    default="creative",
                ),
                "aspect_ratio": model_field_to_node_input(
                    IO.FLOAT,
                    PikaBodyGenerate22C2vGenerate22PikascenesPost,
                    "aspectRatio",
                    step=0.001,
                    min=0.4,
                    max=2.5,
                    default=1.7777777777777777,
                ),
            },
            "optional": {
                "image_ingredient_1": image_ingredient_input,
                "image_ingredient_2": image_ingredient_input,
                "image_ingredient_3": image_ingredient_input,
                "image_ingredient_4": image_ingredient_input,
                "image_ingredient_5": image_ingredient_input,
            },
            "hidden": {
                "auth_token": "AUTH_TOKEN_COMFY_ORG",
            },
        }

    DESCRIPTION = "Combine your images to create a video with the objects in them. Upload multiple images as ingredients and generate a high-quality video that incorporates all of them."
    RETURN_TYPES = ("VIDEO",)

    def api_call(
        self,
        prompt_text: str,
        negative_prompt: str,
        seed: int,
        resolution: str,
        duration: int,
        ingredients_mode: str,
        aspect_ratio: float,
        image_ingredient_1: Optional[torch.Tensor] = None,
        image_ingredient_2: Optional[torch.Tensor] = None,
        image_ingredient_3: Optional[torch.Tensor] = None,
        image_ingredient_4: Optional[torch.Tensor] = None,
        image_ingredient_5: Optional[torch.Tensor] = None,
        auth_token: Optional[str] = None,
    ) -> tuple[VideoFromFile]:
        """API call for Pika Scenes 2.2."""
        all_image_bytes_io = []
        for image in [
            image_ingredient_1,
            image_ingredient_2,
            image_ingredient_3,
            image_ingredient_4,
            image_ingredient_5,
        ]:
            if image is not None:
                image_bytes_io = tensor_to_bytesio(image)
                image_bytes_io.seek(0)
                all_image_bytes_io.append(image_bytes_io)

        # Prepare files data for multipart upload
        pika_files = [
            ("images", (f"image_{i}.png", image_bytes_io, "image/png"))
            for i, image_bytes_io in enumerate(all_image_bytes_io)
        ]

        # Prepare non-file data using the Pydantic model
        pika_request_data = PikaBodyGenerate22C2vGenerate22PikascenesPost(
            ingredientsMode=ingredients_mode,
            promptText=prompt_text,
            negativePrompt=negative_prompt,
            seed=seed,
            resolution=resolution,
            duration=duration,
            aspectRatio=aspect_ratio,
        )

        initial_operation = SynchronousOperation(
            endpoint=ApiEndpoint(
                path=PATH_PIKASCENES,
                method=HttpMethod.POST,
                request_model=PikaBodyGenerate22C2vGenerate22PikascenesPost,
                response_model=PikaGenerateResponse,
            ),
            request=pika_request_data,
            files=pika_files,
            content_type="multipart/form-data",
            auth_token=auth_token,
        )

        return self.execute_task(initial_operation, auth_token)


``` 