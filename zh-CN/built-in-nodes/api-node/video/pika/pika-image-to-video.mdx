---
title: "Pika 2.2 Image to Video - ComfyUI 原生节点文档"
description: "使用Pika的AI技术将静态图像转换为动态视频的节点"
sidebarTitle: "Pika 2.2 Image to Video"
icon: "circle"
---

![ComfyUI 原生 Pika 2.2 Image to Video 节点](/images/built-in-nodes/api_nodes/pika/pika-2-2-image-to-video.jpg)

Pika 2.2 Image to Video 节点通过连接Pika最新的2.2版本API，将静态图像转变为动态视频。该节点能够保留原始图像的视觉特征，同时根据文本提示词添加自然的动态效果。

## 参数说明

### 必需参数

| 参数             | 类型     | 默认值               | 说明                           |
|-----------------|----------|---------------------|-------------------------------|
| image           | 图像      | -                   | 要转换为视频的输入图像            |
| prompt_text     | 字符串    | ""                  | 描述视频动作和内容的文本提示词     |
| negative_prompt | 字符串    | ""                  | 指定不希望在视频中出现的元素       |
| seed            | 整数      | 0                   | 生成过程的随机种子               |
| resolution      | 选择项    | "1080p" | 生成视频的分辨率              |
| duration        | 选择项    | "5s" | 生成视频的持续时间           |

### 输出

| 输出   | 类型   | 说明          |
|--------|--------|--------------|
| VIDEO  | 视频   | 生成的视频结果 |

## 工作流程

节点将输入图像和相关参数（提示词、分辨率、持续时间等）通过多部分表单数据发送到Pika的API服务器。API处理后返回生成的视频结果。用户可以通过调整提示词、负面提示词、随机种子等参数来控制生成效果。

## 源码参考

[节点源码 (更新于2025-05-05)]

```python

class PikaImageToVideoV2_2(PikaNodeBase):
    """Pika 2.2 Image to Video Node."""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": (
                    IO.IMAGE,
                    {"tooltip": "The image to convert to video"},
                ),
                **cls.get_base_inputs_types(PikaBodyGenerate22I2vGenerate22I2vPost),
            },
            "hidden": {
                "auth_token": "AUTH_TOKEN_COMFY_ORG",
            },
        }

    DESCRIPTION = "Sends an image and prompt to the Pika API v2.2 to generate a video."
    RETURN_TYPES = ("VIDEO",)

    def api_call(
        self,
        image: torch.Tensor,
        prompt_text: str,
        negative_prompt: str,
        seed: int,
        resolution: str,
        duration: int,
        auth_token: Optional[str] = None,
    ) -> tuple[VideoFromFile]:
        """API call for Pika 2.2 Image to Video."""
        # Convert image to BytesIO
        image_bytes_io = tensor_to_bytesio(image)
        image_bytes_io.seek(0)  # Reset stream position

        # Prepare file data for multipart upload
        pika_files = {"image": ("image.png", image_bytes_io, "image/png")}

        # Prepare non-file data using the Pydantic model
        pika_request_data = PikaBodyGenerate22I2vGenerate22I2vPost(
            promptText=prompt_text,
            negativePrompt=negative_prompt,
            seed=seed,
            resolution=resolution,
            duration=duration,
        )

        initial_operation = SynchronousOperation(
            endpoint=ApiEndpoint(
                path=PATH_IMAGE_TO_VIDEO,
                method=HttpMethod.POST,
                request_model=PikaBodyGenerate22I2vGenerate22I2vPost,
                response_model=PikaGenerateResponse,
            ),
            request=pika_request_data,
            files=pika_files,
            content_type="multipart/form-data",
            auth_token=auth_token,
        )

        return self.execute_task(initial_operation, auth_token)

``` 