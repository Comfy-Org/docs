 ---
title: "Stability AI Stable Diffusion 3.5 - ComfyUI 原生节点文档"
description: "使用Stability AI的Stable Diffusion 3.5模型生成高质量图像的节点"
sidebarTitle: "Stability AI SD 3.5 Image"
icon: "circle"
---

![ComfyUI 原生 Stability AI Stable Diffusion 3.5 节点](/images/built-in-nodes/api_nodes/stability-ai/stability-ai-stable-image-sd-3-5.jpg)

Stability AI Stable Diffusion 3.5 Image 节点使用 Stability AI 的 Stable Diffusion 3.5 API 生成高质量图像。它支持文本到图像和图像到图像的生成，能够根据文本提示词创建详细的视觉内容。

## 参数说明

### 必需参数

| 参数          | 类型   | 默认值 | 说明                                                                            |
| ------------ | ----- | ------ | ------------------------------------------------------------------------------ |
| prompt       | 字符串 | ""     | 您希望在输出图像中看到的内容。强有力、描述性的提示词，清晰定义元素、颜色和主题将带来更好的结果 |
| model        | 选择项 | -      | 选择使用的Stability SD 3.5模型                                                   |
| aspect_ratio | 选择项 | "1:1"  | 生成图像的宽高比                                                                  |
| style_preset | 选择项 | "None" | 可选的期望图像风格预设                                                             |
| cfg_scale    | 浮点数 | 4.0    | 扩散过程对提示文本的遵循程度（更高的值使图像更接近您的提示词）。范围：1.0 - 10.0，步长：0.1    |
| seed         | 整数   | 0      | 用于创建噪声的随机种子，范围0-4294967294                                             |

### 可选参数

| 参数             | 类型   | 默认值 | 说明                                                                                                            |
| --------------- | ------ | ------ | ------------------------------------------------------------------------------------------------------------ |
| image           | 图像   | -      | 输入图像。当提供图像时，节点将切换到图像到图像模式                                                                    |
| negative_prompt | 字符串 | ""     | 您不希望在输出图像中看到的关键词。这是一个高级功能                                                                     |
| image_denoise   | 浮点数 | 0.5    | 输入图像的去噪程度。0.0产生与输入完全相同的图像，1.0则相当于没有提供任何图像。范围：0.0 - 1.0，步长：0.01。仅在提供输入图像时有效 |

### 输出

| 输出   | 类型 | 说明      |
| ----- | ---- | -------- |
| IMAGE | 图像 | 生成的图像 |


## 使用示例

<Card title="Stability AI Stable Diffusion 3.5 Image 工作流示例" icon="book" href="/zh-CN/tutorials/api-nodes/stability-ai/stability-ai-stable-diffusion-3-5-image">
Stability AI Stable Diffusion 3.5 Image 工作流示例
</Card>

## 注意事项

- 当提供输入图像时，节点将从文本到图像模式切换到图像到图像模式
- 在图像到图像模式下，宽高比参数将被忽略
- 模式选择会根据是否提供图像自动切换：
  - 未提供图像：文本到图像模式
  - 提供图像：图像到图像模式
- 如果style_preset设置为"None"，则不会应用任何预设风格

## 源码

[节点源码 (更新于2025-05-07)]

```python
class StabilityStableImageSD_3_5Node:
    """
    Generates images synchronously based on prompt and resolution.
    """

    RETURN_TYPES = (IO.IMAGE,)
    DESCRIPTION = cleandoc(__doc__ or "")  # Handle potential None value
    FUNCTION = "api_call"
    API_NODE = True
    CATEGORY = "api node/image/Stability AI"

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "prompt": (
                    IO.STRING,
                    {
                        "multiline": True,
                        "default": "",
                        "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results."
                    },
                ),
                "model": ([x.value for x in Stability_SD3_5_Model],),
                "aspect_ratio": ([x.value for x in StabilityAspectRatio],
                    {
                        "default": StabilityAspectRatio.ratio_1_1,
                        "tooltip": "Aspect ratio of generated image.",
                    },
                ),
                "style_preset": (get_stability_style_presets(),
                    {
                        "tooltip": "Optional desired style of generated image.",
                    },
                ),
                "cfg_scale": (
                    IO.FLOAT,
                    {
                        "default": 4.0,
                        "min": 1.0,
                        "max": 10.0,
                        "step": 0.1,
                        "tooltip": "How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt)",
                    },
                ),
                "seed": (
                    IO.INT,
                    {
                        "default": 0,
                        "min": 0,
                        "max": 4294967294,
                        "control_after_generate": True,
                        "tooltip": "The random seed used for creating the noise.",
                    },
                ),
            },
            "optional": {
                "image": (IO.IMAGE,),
                "negative_prompt": (
                    IO.STRING,
                    {
                        "default": "",
                        "forceInput": True,
                        "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature."
                    },
                ),
                "image_denoise": (
                    IO.FLOAT,
                    {
                        "default": 0.5,
                        "min": 0.0,
                        "max": 1.0,
                        "step": 0.01,
                        "tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.",
                    },
                ),
            },
            "hidden": {
                "auth_token": "AUTH_TOKEN_COMFY_ORG",
            },
        }

    def api_call(self, model: str, prompt: str, aspect_ratio: str, style_preset: str, seed: int, cfg_scale: float,
                 negative_prompt: str=None, image: torch.Tensor = None, image_denoise: float=None,
                 auth_token=None):
        validate_string(prompt, strip_whitespace=False)
        # prepare image binary if image present
        image_binary = None
        mode = Stability_SD3_5_GenerationMode.text_to_image
        if image is not None:
            image_binary = tensor_to_bytesio(image, total_pixels=1504*1504).read()
            mode = Stability_SD3_5_GenerationMode.image_to_image
            aspect_ratio = None
        else:
            image_denoise = None

        if not negative_prompt:
            negative_prompt = None
        if style_preset == "None":
            style_preset = None

        files = {
            "image": image_binary
        }

        operation = SynchronousOperation(
            endpoint=ApiEndpoint(
                path="/proxy/stability/v2beta/stable-image/generate/sd3",
                method=HttpMethod.POST,
                request_model=StabilityStable3_5Request,
                response_model=StabilityStableUltraResponse,
            ),
            request=StabilityStable3_5Request(
                prompt=prompt,
                negative_prompt=negative_prompt,
                aspect_ratio=aspect_ratio,
                seed=seed,
                strength=image_denoise,
                style_preset=style_preset,
                cfg_scale=cfg_scale,
                model=model,
                mode=mode,
            ),
            files=files,
            content_type="multipart/form-data",
            auth_token=auth_token,
        )
        response_api = operation.execute()

        if response_api.finish_reason != "SUCCESS":
            raise Exception(f"Stable Diffusion 3.5 Image generation failed: {response_api.finish_reason}.")

        image_data = base64.b64decode(response_api.image)
        returned_image = bytesio_to_image_tensor(BytesIO(image_data))

        return (returned_image,)
```

