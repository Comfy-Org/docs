---
title: "Stability Stable Image Ultra - ComfyUI 原生节点文档"
description: "使用Stability AI的超级稳定扩散模型生成高质量图像的节点"
sidebarTitle: "Stability Stable Image Ultra"
icon: "circle"
---

![ComfyUI 原生 Stability Stable Image Ultra 节点](/images/built-in-nodes/api_nodes/stability/stability-stable-image-ultra.jpg)

Stability Stable Image Ultra 节点允许你使用Stability AI最先进的文本到图像和图像到图像生成模型创建精美的视觉内容。

## 节点功能

此节点连接到Stability AI的Stable Diffusion Ultra API，让用户能够通过详细的文本提示词生成高质量图像。Stability AI以其尖端的图像生成技术闻名，提供极高的详细度、精确的提示理解和出色的艺术表现力。

## 参数说明

### 基本参数

| 参数 | 类型 | 默认值 | 说明 |
|-----|-----|-------|------|
| prompt | 字符串 | "" | 详细描述要生成内容的文本提示词 |
| aspect_ratio | 选择项 | "1:1" | 输出图像的宽高比 |
| cfg_scale | 浮点数 | 7.0 | 控制对提示词的遵循程度(1-35) |
| seed | 整数 | 0 | 生成的随机种子 |
| style_preset | 选择项 | "None" | 预设的视觉风格 |

### 图像到图像参数

| 参数 | 类型 | 说明 |
|-----|-----|------|
| image | 图像 | 用于图像到图像生成的输入图像 |
| strength | 浮点数 | 控制对原始图像的修改程度(0-1) |

### 可选参数

| 参数 | 类型 | 说明 |
|-----|-----|------|
| negative_prompt | 字符串 | 指定不希望在图像中出现的元素 |

### 输出

| 输出 | 类型 | 说明 |
|-----|-----|------|
| IMAGE | 图像 | 生成的图像结果 |

## 使用示例



## 工作原理

Stability Stable Image Ultra 节点利用Stability AI的最新Stable Diffusion 3模型处理用户提供的文本提示词。该模型通过深度学习理解提示词的语义内容，并将其转换为高度详细的视觉表现。

在文本到图像模式下，节点完全基于提示词生成全新图像。在图像到图像模式下，它分析输入图像的内容和结构，然后根据提示词和强度设置进行有针对性的修改。

用户可以通过调整CFG比例来控制生成过程对提示词的严格遵循程度，较高的值会产生更加忠实于提示词的结果。样式预设选项则允许用户快速应用预定义的视觉风格，如摄影、动漫、油画等。

## 源码参考

[节点源码 (更新于2025-05-03)]

```python

class StabilityStableImageUltraNode:
    """
    Generates images synchronously based on prompt and resolution.
    """

    RETURN_TYPES = (IO.IMAGE,)
    DESCRIPTION = cleandoc(__doc__ or "")  # Handle potential None value
    FUNCTION = "api_call"
    API_NODE = True
    CATEGORY = "api node/image/stability"

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "prompt": (
                    IO.STRING,
                    {
                        "multiline": True,
                        "default": "",
                        "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines" +
                                    "What you wish to see in the output image. A strong, descriptive prompt that clearly defines" +
                                    "elements, colors, and subjects will lead to better results. " +
                                    "To control the weight of a given word use the format `(word:weight)`," +
                                    "where `word` is the word you'd like to control the weight of and `weight`" +
                                    "is a value between 0 and 1. For example: `The sky was a crisp (blue:0.3) and (green:0.8)`" +
                                    "would convey a sky that was blue and green, but more green than blue."
                    },
                ),
                "aspect_ratio": ([x.value for x in StabilityAspectRatio],
                    {
                        "default": StabilityAspectRatio.ratio_1_1,
                        "tooltip": "Aspect ratio of generated image.",
                    },
                ),
                "style_preset": (get_stability_style_presets(),
                    {
                        "tooltip": "Optional desired style of generated image.",
                    },
                ),
                "seed": (
                    IO.INT,
                    {
                        "default": 0,
                        "min": 0,
                        "max": 4294967294,
                        "control_after_generate": True,
                        "tooltip": "The random seed used for creating the noise.",
                    },
                ),
            },
            "optional": {
                "image": (IO.IMAGE,),
                "negative_prompt": (
                    IO.STRING,
                    {
                        "default": "",
                        "forceInput": True,
                        "tooltip": "A blurb of text describing what you do not wish to see in the output image. This is an advanced feature."
                    },
                ),
                "image_denoise": (
                    IO.FLOAT,
                    {
                        "default": 0.5,
                        "min": 0.0,
                        "max": 1.0,
                        "step": 0.01,
                        "tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.",
                    },
                ),
            },
            "hidden": {
                "auth_token": "AUTH_TOKEN_COMFY_ORG",
            },
        }

    def api_call(self, prompt: str, aspect_ratio: str, style_preset: str, seed: int,
                 negative_prompt: str=None, image: torch.Tensor = None, image_denoise: float=None,
                 auth_token=None):
        # prepare image binary if image present
        image_binary = None
        if image is not None:
            image_binary = tensor_to_bytesio(image, 1504 * 1504).read()
        else:
            image_denoise = None

        if not negative_prompt:
            negative_prompt = None
        if style_preset == "None":
            style_preset = None

        files = {
            "image": image_binary
        }

        operation = SynchronousOperation(
            endpoint=ApiEndpoint(
                path="/proxy/stability/v2beta/stable-image/generate/ultra",
                method=HttpMethod.POST,
                request_model=StabilityStableUltraRequest,
                response_model=StabilityStableUltraResponse,
            ),
            request=StabilityStableUltraRequest(
                prompt=prompt,
                negative_prompt=negative_prompt,
                aspect_ratio=aspect_ratio,
                seed=seed,
                strength=image_denoise,
                style_preset=style_preset,
            ),
            files=files,
            content_type="multipart/form-data",
            auth_token=auth_token,
        )
        response_api = operation.execute()

        if response_api.finish_reason != "SUCCESS":
            raise Exception(f"Stable Image Ultra generation failed: {response_api.finish_reason}.")

        image_data = base64.b64decode(response_api.image)
        returned_image = bytesio_to_image_tensor(BytesIO(image_data))

        return (returned_image,)


```