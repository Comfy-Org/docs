---
title: "Recraft Remove Background - ComfyUI 原生节点文档"
description: "自动移除图像背景并生成透明Alpha通道的 Recraft API 节点"
sidebarTitle: "Recraft Remove Background"
icon: "circle"
---

![ComfyUI 原生Recraft Remove Background节点](/images/built-in-nodes/api_nodes/recraft/recraft-remove-background.jpg)

Recraft Remove Background 节点能够智能识别并移除图像背景，生成带有透明背景的图像和对应的Alpha蒙版。

## 节点功能

此节点使用AI技术分析图像，自动识别前景主体和背景元素，然后精确移除背景，保留主体对象。处理后的图像保留Alpha透明通道，可以轻松与其他设计元素组合。

## 参数说明

### 基本参数

| 参数 | 类型 | 默认值 | 说明 |
|-----|-----|-------|------|
| image | 图像 | - | 需要移除背景的输入图像 |

### 输出

| 输出 | 类型 | 说明 |
|-----|-----|------|
| IMAGE | 图像 | 移除背景后的图像(带Alpha通道) |
| MASK | 蒙版 | 主体对象的蒙版(白色区域为保留的主体) |

## 使用示例

适用场景:

- 产品摄影：移除商品背景以用于电商平台
- 头像处理：创建透明背景的个人或企业头像
- 设计素材准备：提取对象以用于合成创作
- 视觉营销：准备可与不同背景组合的主体图像

## 工作原理

节点处理流程:

1. 接收输入图像并上传到Recraft服务器
2. AI模型分析图像内容，识别前景主体和背景
3. 精确分割主体对象，生成Alpha蒙版
4. 移除背景并保留透明通道
5. 返回处理后的图像和相应蒙版

该节点处理多种复杂场景，包括头发、半透明物体和细节丰富的边缘。输出的图像保留完整的RGBA颜色信息，而蒙版输出则提供黑白分离图层，便于进一步处理和编辑。

## 源码参考

[节点源码 (更新于2025-05-03)] 

```python
class RecraftRemoveBackgroundNode:
    """
    Remove background from image, and return processed image and mask.
    """

    RETURN_TYPES = (IO.IMAGE, IO.MASK)
    DESCRIPTION = cleandoc(__doc__ or "")  # Handle potential None value
    FUNCTION = "api_call"
    API_NODE = True
    CATEGORY = "api node/image/Recraft"

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image": (IO.IMAGE, ),
            },
            "optional": {
            },
            "hidden": {
                "auth_token": "AUTH_TOKEN_COMFY_ORG",
            },
        }

    def api_call(
        self,
        image: torch.Tensor,
        auth_token=None,
        **kwargs,
    ):
        images = []
        total = image.shape[0]
        pbar = ProgressBar(total)
        for i in range(total):
            sub_bytes = handle_recraft_file_request(
                image=image[i],
                path="/proxy/recraft/images/removeBackground",
                auth_token=auth_token,
            )
            images.append(torch.cat([bytesio_to_image_tensor(x) for x in sub_bytes], dim=0))
            pbar.update(1)

        images_tensor = torch.cat(images, dim=0)
        # use alpha channel as masks, in B,H,W format
        masks_tensor = images_tensor[:,:,:,-1:].squeeze(-1)
        return (images_tensor, masks_tensor)

```