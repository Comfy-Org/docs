---
title: "Luma Image to Image - ComfyUI 原生节点文档"
description: "使用Luma AI修改图像的节点"
sidebarTitle: "Luma Image to Image"
icon: "circle"
---

![ComfyUI 原生 Luma Image to Image 节点](/images/built-in-nodes/api_nodes/luma/luma-image-to-image.jpg)

Luma Image to Image 节点允许你使用Luma AI的技术根据文本提示词修改现有图像，同时保留原始图像的某些特征和结构。

## 节点功能

此节点连接到Luma AI的图像修改API，使用户能够通过文本指令对输入图像进行变换和修改。它保留原始图像的结构和构图，同时应用新的风格、内容或其他创意变化。

## 参数说明

### 基本参数

| 参数 | 类型 | 默认值 | 说明 |
|-----|-----|-------|------|
| image | 图像 | - | 要修改的输入图像 |
| prompt | 字符串 | "" | 描述如何修改图像的文本提示词 |
| strength | 浮点数 | 0.7 | 控制修改程度 (0-1)，越高变化越大 |
| guidance_scale | 浮点数 | 7.5 | 控制对提示词的遵循程度 |
| num_images | 整数 | 1 | 生成的变体数量 |

### 可选参数

| 参数 | 类型 | 说明 |
|-----|-----|------|
| negative_prompt | 字符串 | 指定不希望在修改后图像中出现的元素 |
| luma_concepts | LUMA_CONCEPT | 用于调整生成风格的概念引导 |
| luma_ref | LUMA_REF | 额外的参考图像以影响生成结果 |

### 输出

| 输出 | 类型 | 说明 |
|-----|-----|------|
| IMAGE | 图像 | 修改后的图像结果 |

## 使用示例

## 工作原理

Luma Image to Image 节点分析输入图像并结合文本提示词来引导修改过程。它使用Luma AI的生成模型，既考虑原始图像的特征，又根据提示词应用新的元素和变化。

节点的强度参数决定了原始图像被保留的程度，较低的强度值会产生更接近原始图像的结果，而较高的值则允许更激进的变化。此外，用户可以通过负面提示词、概念引导和参考图像来进一步精细控制生成过程。

## 源码参考

[节点源码 (更新于2025-05-03)] 

```python

class LumaImageModifyNode(ComfyNodeABC):
    """
    Modifies images synchronously based on prompt and aspect ratio.
    """

    RETURN_TYPES = (IO.IMAGE,)
    DESCRIPTION = cleandoc(__doc__ or "")  # Handle potential None value
    FUNCTION = "api_call"
    API_NODE = True
    CATEGORY = "api node/image/Luma"

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "image": (IO.IMAGE,),
                "prompt": (
                    IO.STRING,
                    {
                        "multiline": True,
                        "default": "",
                        "tooltip": "Prompt for the image generation",
                    },
                ),
                "image_weight": (
                    IO.FLOAT,
                    {
                        "default": 1.0,
                        "min": 0.0,
                        "max": 1.0,
                        "step": 0.01,
                        "tooltip": "Weight of the image; the closer to 0.0, the less the image will be modified.",
                    },
                ),
                "model": ([model.value for model in LumaImageModel],),
                "seed": (
                    IO.INT,
                    {
                        "default": 0,
                        "min": 0,
                        "max": 0xFFFFFFFFFFFFFFFF,
                        "control_after_generate": True,
                        "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
                    },
                ),
            },
            "optional": {},
            "hidden": {
                "auth_token": "AUTH_TOKEN_COMFY_ORG",
            },
        }

    def api_call(
        self,
        prompt: str,
        model: str,
        image: torch.Tensor,
        image_weight: float,
        seed,
        auth_token=None,
        **kwargs,
    ):
        # first, upload image
        download_urls = upload_images_to_comfyapi(
            image, max_images=1, auth_token=auth_token
        )
        image_url = download_urls[0]
        # next, make Luma call with download url provided
        operation = SynchronousOperation(
            endpoint=ApiEndpoint(
                path="/proxy/luma/generations/image",
                method=HttpMethod.POST,
                request_model=LumaImageGenerationRequest,
                response_model=LumaGeneration,
            ),
            request=LumaImageGenerationRequest(
                prompt=prompt,
                model=model,
                modify_image_ref=LumaModifyImageRef(
                    url=image_url, weight=round(image_weight, 2)
                ),
            ),
            auth_token=auth_token,
        )
        response_api: LumaGeneration = operation.execute()

        operation = PollingOperation(
            poll_endpoint=ApiEndpoint(
                path=f"/proxy/luma/generations/{response_api.id}",
                method=HttpMethod.GET,
                request_model=EmptyRequest,
                response_model=LumaGeneration,
            ),
            completed_statuses=[LumaState.completed],
            failed_statuses=[LumaState.failed],
            status_extractor=lambda x: x.state,
            auth_token=auth_token,
        )
        response_poll = operation.execute()

        img_response = requests.get(response_poll.assets.image)
        img = process_image_response(img_response)
        return (img,)

```