---
title: "首次图片生成"
description: "本部分教程将会带你完成首次 ComfyUI 的图片生成"
---

本篇目的主要带你初步了解 ComfyUI 的文生图功能，并完成首次图片的生成

由于在各版本的 ComfyUI 的初始安装中，通常并不具备对应的绘图模型，本篇教程将引导你完成以下步骤
1. 学会加载示例工作流
2. 学会模型自动安装及安装位置
3. 学会使用对应的 AI 绘图模型进行一次文本到图片的生成


## 基础知识讲解

### 关于文生图

文生图（Text to Image），是 AI 绘图的基础，通过输入文本描述来生成对应的图片，是 AI 绘图最常用的功能之一。

文生图通常需要几个基础条件作为条件输入

- 正向提示词: 你想要出现在画面里的内容
- 负向提示词：你不想出现在画面里的内容
- 绘图模型：用于绘图的模型，不同的模型你可以理解为用于

整个图片生成过程，你可以理解成你把你的**绘图要求(正向提示词、负向提示词)**告诉一个**画家(绘图模型)**，画家会根据你的要求，画出你想要的内容，在本篇中将使用 SD1.5 作为我们使用的基础模型

### SD1.5 模型简介

**SD1.5(Stable Diffusion 1.5)**是一个由[Stability AI](https://stability.ai/)开发的AI绘图模型，Stable Diffusion系列的基础版本，于2022年发布。SD1.5 是基于 **512×512** 分辨率图片训练，所以其对 **512×512** 分辨率图片生成支持较好，体积约为4GB，可以在**消费级显卡（如6GB显存）**上流畅运行。目前 SD1.5 的相关周边生态非常丰富，它支持广泛的插件（如ControlNet、LoRA）和优化工具。

它的轻量化、兼容性强和丰富的社区生态，使其成为AI图像生成领域的经典入门模型。

模型特点：

优点：
- 使用门槛低，生态成熟
- 支持二次元、写实、卡通等多种风格
- 生成速度快

缺点：
- 原生处理高分辨率时可能出现多主体问题
- 复杂细节（如手部、光影层次）易出错
- 对于复杂提示词理解能力不足

## ComfyUI 文生图工作流教程讲解

### 1. 启动 ComfyUI

请确定你已经按照安装部分的指南完成了 ComfyUI 的启动，并可以成功打开 ComfyUI 的页面

![ComfyUI界面](/images/interface/comfyui-boot-screen.jpg)

### 2. 加载默认文生图工作流

正常情况下，打开 ComfyUI 后是会自动加载默认的文生图工作流的, 如果对应的界面内容为空，请参考下图进行工作流的加载，如加载成功，则请忽略这部分的说明

![](/images/tutorial/gettingstarted/first-image-generation-1.jpg)
请对照图片中序号所对应的顺序进行操作
1. 点击 ComfyUI 界面右下角的**Fit View**按钮，防止已加载工作流是在视图外导致不可见
2. 点击侧边栏的**文件夹图标（workflows）**
3. 点击 工作流（Workflows）面板顶部的**浏览工作流示例（Browse example workflows）** 按钮

下图继续

![加载工作流](/images/tutorial/gettingstarted/first-image-generation-2-load-workflow.jpg)

4. 选择默认的第一个工作流 **Image Generation** 以加载图标

### 3. 自动或者手动绘图模型

如果你的电脑上没有安装[v1-5-pruned-emaonly-fp16.safetensors](https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/blob/main/v1-5-pruned-emaonly-fp16.safetensors) 这个模型时，在加载文生图工作流后会自动提示你下载这个模型，如下图所示

![模型缺失](/images/tutorial/gettingstarted/first-image-generation-3-missing-models.jpg)

这是 ComfyUI 的自动检测机制，如果加载的工作流存在模型 / 节点缺失，则会出现自动提示

在这一步你可以选择：
1. 点击**Download**让 ComfyUI 自动完成对应的模型的下载
2. 如果下载失败，或者你的网络情况不能够顺利访问下载源，请参考手动下载部分说明

#### 3.1 自动下载模型

点击**Download**按钮后，ComfyUI 将会执行安装程序，你可以等待安装完成或者在侧边栏的模型面板里查看安装进度

如果长时间未下载成功，请尝试本章节手动安装模型的说明

#### 3.2 手动完成模型的安装

请访问右侧的模型地址：[前往下载 v1-5-pruned-emaonly-fp16.safetensors](https://huggingface.co/Comfy-Org/stable-diffusion-v1-5-archive/blob/main/v1-5-pruned-emaonly-fp16.safetensors)

参考下面图片完成对应模型的下载

![Hugging Face 模型下载](/images/tutorial/gettingstarted/first-image-generation-5-hugging-face.jpg)

下载完成后，请将对应的**v1-5-pruned-emaonly-fp16.safetensors** 文件保存到以下位置

<Tabs>
  <Tab title="ComfyUI 桌面版">

    请找到你在安装过程中设置的 ComfyUI 安装位置，将对应模型文件保存到以下文件夹位置 `<你的 ComfyUI 安装位置>/ComfyUI/models/checkpoints`

    ![ComfyUI 桌面版模型保存位置](/images/tutorial/gettingstarted/first-image-generation-6-2-desktop.jpg)

  </Tab>
  <Tab title="ComfyUI便携版本">
   找到你解压后的便携版的文件夹，在**ComfyUI_windows_portable/ComfyUI/models/checkpoints** 文件夹下完成模型的保存
    ![ComfyUI 便携版模型保存位置](/images/tutorial/gettingstarted/first-image-generation-6-1-portable.jpg)
  </Tab>
 <Tab title="其它版本">
  请参考 桌面版和便携版部分的说明查找 **ComfyUI/models/checkpoints**文件夹位置
  </Tab>
</Tabs>

完成对应保存操作后，请刷新或者重启 ComfyUI 保证对应模型可以被 ComfyUI 检测

### 4. 加载模型，并进行第一次图片生成

在完成了对应的绘图模型安装后，请参考下图步骤加载对应的模型，并进行第一次图片的生成

![图片生成](/images/tutorial/gettingstarted/first-image-generation-7-queue.jpg)
请对应图片序号，完成下面操作
1. 请在**Load Checkpoint** 节点使用箭头或者点击文本区域确保 **v1-5-pruned-emaonly-fp16.safetensors** 被选中，且左右切换箭头不会出现**null** 的文本
2. 点击 `Queue` 按钮，或者使用快捷键 `Ctrl + enter(回车)` 来执行图片生成

等待对应流程执行完成后，你应该可以在界面的**保存图像（Save Image）**节点中看到对应的图片结果，可以在上面右键保存到本地

![ComfyUI 首次图片生成结果](/images/tutorial/gettingstarted/first-image-generation-8-result.jpg)

### 5. 工作流讲解

![ComfyUI 文生图工作流讲解](/images/tutorial/gettingstarted/first-image-generation-9-explain.jpg)

如图所示，不同节点的功能作用说明如下：
A. **加载模型（Load Checkpoint）** ：用于加载绘图模型
B. **CLIP文本编码器（CLIP Text Encoder）** ：用于编码提示词，也就是输入你对画面的要求，连接到 Ksampler 节点的`Positive`的为正向提示词，连接到 Ksampler 节点的`Negative`的为负向提示词
C. **空Latent图像（Empty Latent Image）** ：定义一个潜在空间，你可以理解为画布尺寸的大小
D. **K 采样器（Ksampler）** ：对输入的条件进行在潜空间进行处理生成对应的潜空间图像
E. **VAE 解码（VAE Decode）** ：将潜空间图像转换为图片
F. **Save Image** ：预览并保存从潜空间解码的图片，并保存到本地`ComfyUI/output`文件夹下

你可以尝试修改**CLIP Text Encoder**处的文本，来查看不同提示词带来的不同效果，或者生成你想要的画面
### 6. 开始你自己的尝试

你可以尝试修改**CLIP Text Encoder**处的文本，来查看不同提示词带来的不同效果，或者生成你想要的画面，下面是针对 SD1.5 模型的一些简单原则
- 尽量使用英文
- 使用短语而不是长句子
- 使用更具体的描述
- 可以使用类似 `(golden hour:1.2)` 这样的表达来提升特定关键词的权重，这样它在画面中出现的概率会更高，`1.2` 为权重，`golden hour` 为关键词
- 可以使用类似 `masterpiece, best quality, 4k` 等关键词来提升生成质量

下面是几组不同的 prompt 示例，你可以尝试使用这些 prompt 来查看生成的效果，或者使用你自己的 prompt 来尝试生成

1. 二次元动漫风格

正向提示词：
```
anime style, 1girl with long pink hair, cherry blossom background, studio ghibli aesthetic, soft lighting, intricate details

masterpiece, best quality, 4k
```

负向提示词：
```
low quality, blurry, deformed hands, extra fingers
```

2. 写实风格

正向提示词：
```
(ultra realistic portrait:1.3), (elegant woman in crimson silk dress:1.2), 
full body, soft cinematic lighting, (golden hour:1.2), 
(fujifilm XT4:1.1), shallow depth of field, 
(skin texture details:1.3), (film grain:1.1), 
gentle wind flow, warm color grading, (perfect facial symmetry:1.3)
```

负向提示词：
```
(deformed, cartoon, anime, doll, plastic skin, overexposed, blurry, extra fingers)
```

3. 特定艺术家风格

正向提示词：
```
fantasy elf, detailed character, glowing magic, vibrant colors, long flowing hair, elegant armor, ethereal beauty, mystical forest, magical aura, high detail, soft lighting, fantasy portrait, Artgerm style
```

负向提示词：
```
blurry, low detail, cartoonish, unrealistic anatomy, out of focus, cluttered, flat lighting
```

## 故障排除

### 1. 模型加载问题

如果 `Load Checkpoint` 节点没有任何模型可以选择，请先确认你的模型安装位置正确，或者尝试**刷新浏览器**或者**重启 ComfyUI** 使得对应文件夹下的模型可以被检测到

### 2. 图像质量提升

如果出现手部畸形等问题，建议：

- 在负向提示词中添加"deformed hands, extra fingers"
- 使用ADetailer等后处理插件
- 适当提高CFG值（不超过12）
